I0928 00:15:06.303586 29269 caffe.cpp:113] Use GPU with device ID 0
I0928 00:15:06.430243 29269 caffe.cpp:121] Starting Optimization
I0928 00:15:06.430327 29269 solver.cpp:32] Initializing solver from parameters: 
test_iter: 140
test_interval: 1000
base_lr: 0.00281
display: 20
max_iter: 20000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 10000
snapshot: 1000
snapshot_prefix: "snapshots_iter4_ensemble_orderless/snapshots_s1"
solver_mode: GPU
net: "prototxts/test_print_1.prototxt"
I0928 00:15:06.430395 29269 solver.cpp:70] Creating training net from net file: prototxts/test_print_1.prototxt
I0928 00:15:06.431339 29269 net.cpp:261] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_action
I0928 00:15:06.431371 29269 net.cpp:261] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_frame
I0928 00:15:06.431587 29269 net.cpp:42] Initializing net from parameters: 
name: "CaffeNet"
force_backward: true
state {
  phase: TRAIN
}
layer {
  name: "data_action"
  type: "Data"
  top: "data_action"
  top: "label_action"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "imagenet_mean.binaryproto"
  }
  data_param {
    source: "/media/storage/zhiweid/CollectiveActivityDataset/databases/CAD_action_train_lmdb_0903"
    batch_size: 70
    backend: LMDB
  }
}
layer {
  name: "conv1_action"
  type: "Convolution"
  bottom: "data_action"
  top: "conv1_action"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_action"
  type: "ReLU"
  bottom: "conv1_action"
  top: "conv1_action"
}
layer {
  name: "pool1_action"
  type: "Pooling"
  bottom: "conv1_action"
  top: "pool1_action"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1_action"
  type: "LRN"
  bottom: "pool1_action"
  top: "norm1_action"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2_action"
  type: "Convolution"
  bottom: "norm1_action"
  top: "conv2_action"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2_action"
  type: "ReLU"
  bottom: "conv2_action"
  top: "conv2_action"
}
layer {
  name: "pool2_action"
  type: "Pooling"
  bottom: "conv2_action"
  top: "pool2_action"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2_action"
  type: "LRN"
  bottom: "pool2_action"
  top: "norm2_action"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3_action"
  type: "Convolution"
  bottom: "norm2_action"
  top: "conv3_action"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_action"
  type: "ReLU"
  bottom: "conv3_action"
  top: "conv3_action"
}
layer {
  name: "conv4_action"
  type: "Convolution"
  bottom: "conv3_action"
  top: "conv4_action"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4_action"
  type: "ReLU"
  bottom: "conv4_action"
  top: "conv4_action"
}
layer {
  name: "conv5_action"
  type: "Convolution"
  bottom: "conv4_action"
  top: "conv5_action"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5_action"
  type: "ReLU"
  bottom: "conv5_action"
  top: "conv5_action"
}
layer {
  name: "pool5_action"
  type: "Pooling"
  bottom: "conv5_action"
  top: "pool5_action"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6_action"
  type: "InnerProduct"
  bottom: "pool5_action"
  top: "fc6_action"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6_action"
  type: "ReLU"
  bottom: "fc6_action"
  top: "fc6_action"
}
layer {
  name: "drop6_action"
  type: "Dropout"
  bottom: "fc6_action"
  top: "fc6_action"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_action"
  type: "InnerProduct"
  bottom: "fc6_action"
  top: "fc7_action"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7_action"
  type: "ReLU"
  bottom: "fc7_action"
  top: "fc7_action"
}
layer {
  name: "drop7_action"
  type: "Dropout"
  bottom: "fc7_action"
  top: "fc7_action"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_CAD_action"
  type: "InnerProduct"
  bottom: "fc7_action"
  top: "fc8_CAD_action"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  inner_product_param {
    num_output: 7
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "data_frame"
  type: "Data"
  top: "data_frame"
  top: "label_frame"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "imagenet_mean.binaryproto"
  }
  data_param {
    source: "/media/storage/zhiweid/CollectiveActivityDataset/databases/CAD_frame_train_lmdb_0903"
    batch_size: 5
    backend: LMDB
  }
}
layer {
  name: "conv1_frame"
  type: "Convolution"
  bottom: "data_frame"
  top: "conv1_frame"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_frame"
  type: "ReLU"
  bottom: "conv1_frame"
  top: "conv1_frame"
}
layer {
  name: "pool1_frame"
  type: "Pooling"
  bottom: "conv1_frame"
  top: "pool1_frame"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1_frame"
  type: "LRN"
  bottom: "pool1_frame"
  top: "norm1_frame"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2_frame"
  type: "Convolution"
  bottom: "norm1_frame"
  top: "conv2_frame"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2_frame"
  type: "ReLU"
  bottom: "conv2_frame"
  top: "conv2_frame"
}
layer {
  name: "pool2_frame"
  type: "Pooling"
  bottom: "conv2_frame"
  top: "pool2_frame"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2_frame"
  type: "LRN"
  bottom: "pool2_frame"
  top: "norm2_frame"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3_frame"
  type: "Convolution"
  bottom: "norm2_frame"
  top: "conv3_frame"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_frame"
  type: "ReLU"
  bottom: "conv3_frame"
  top: "conv3_frame"
}
layer {
  name: "conv4_frame"
  type: "Convolution"
  bottom: "conv3_frame"
  top: "conv4_frame"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4_frame"
  type: "ReLU"
  bottom: "conv4_frame"
  top: "conv4_frame"
}
layer {
  name: "conv5_frame"
  type: "Convolution"
  bottom: "conv4_frame"
  top: "conv5_frame"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5_frame"
  type: "ReLU"
  bottom: "conv5_frame"
  top: "conv5_frame"
}
layer {
  name: "pool5_frame"
  type: "Pooling"
  bottom: "conv5_frame"
  top: "pool5_frame"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6_frame"
  type: "InnerProduct"
  bottom: "pool5_frame"
  top: "fc6_frame"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6_frame"
  type: "ReLU"
  bottom: "fc6_frame"
  top: "fc6_frame"
}
layer {
  name: "drop6_frame"
  type: "Dropout"
  bottom: "fc6_frame"
  top: "fc6_frame"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_frame"
  type: "InnerProduct"
  bottom: "fc6_frame"
  top: "fc7_frame"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7_frame"
  type: "ReLU"
  bottom: "fc7_frame"
  top: "fc7_frame"
}
layer {
  name: "drop7_frame"
  type: "Dropout"
  bottom: "fc7_frame"
  top: "fc7_frame"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_CAD_frame"
  type: "InnerProduct"
  bottom: "fc7_frame"
  top: "fc8_CAD_frame"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  inner_product_param {
    num_output: 5
    bias_term: true
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "prob_frame"
  type: "Softmax"
  bottom: "fc8_CAD_frame"
  top: "fc8_CAD_frame_prob"
}
layer {
  name: "prob_action"
  type: "Softmax"
  bottom: "fc8_CAD_action"
  top: "fc8_CAD_prob"
}
layer {
  name: "Data_arrange_layer_filter"
  type: "Python"
  bottom: "fc8_CAD_action"
  bottom: "label_action"
  top: "fc9_filtered"
  python_param {
    module: "Data_arrange"
    layer: "Data_Arrange_Layer"
  }
}
layer {
  name: "concatenation_s_a_p"
  type: "Concat"
  bottom: "fc8_CAD_frame_prob"
  bottom: "fc9_filtered"
  top: "concat_all"
  concat_param {
    concat_dim: 1
  }
}
layer {
  name: "simplified_message_in"
  type: "Python"
  bottom: "concat_all"
  bottom: "label_action"
  top: "a2a"
  top: "s2a"
  top: "a2s"
  python_param {
    module: "simplified_message_in"
    layer: "simplified_message_in"
  }
}
I0928 00:15:06.432000 29269 net.cpp:67] Memory required for data: 0
I0928 00:15:06.432122 29269 layer_factory.hpp:74] Creating layer data_action
I0928 00:15:06.432163 29269 net.cpp:84] Creating Layer data_action
I0928 00:15:06.432175 29269 net.cpp:342] data_action -> data_action
I0928 00:15:06.432238 29269 net.cpp:342] data_action -> label_action
I0928 00:15:06.432257 29269 net.cpp:113] Setting up data_action
I0928 00:15:06.432317 29269 db.cpp:34] Opened lmdb /media/storage/zhiweid/CollectiveActivityDataset/databases/CAD_action_train_lmdb_0903
I0928 00:15:06.432515 29269 data_layer.cpp:67] output data size: 70,3,227,227
I0928 00:15:06.432526 29269 data_transformer.cpp:22] Loading mean file from: imagenet_mean.binaryproto
I0928 00:15:06.443650 29269 base_data_layer.cpp:43] Initializing prefetch
I0928 00:15:06.443717 29269 base_data_layer.cpp:45] Prefetch initialized.
I0928 00:15:06.443737 29269 net.cpp:120] Top shape: 70 3 227 227 (10821090)
I0928 00:15:06.443742 29269 net.cpp:120] Top shape: 70 (70)
I0928 00:15:06.443745 29269 net.cpp:126] Memory required for data: 43284640
I0928 00:15:06.443753 29269 layer_factory.hpp:74] Creating layer label_action_data_action_1_split
I0928 00:15:06.443769 29269 net.cpp:84] Creating Layer label_action_data_action_1_split
I0928 00:15:06.443779 29269 net.cpp:384] label_action_data_action_1_split <- label_action
I0928 00:15:06.443799 29269 net.cpp:342] label_action_data_action_1_split -> label_action_data_action_1_split_0
I0928 00:15:06.443812 29269 net.cpp:342] label_action_data_action_1_split -> label_action_data_action_1_split_1
I0928 00:15:06.443821 29269 net.cpp:113] Setting up label_action_data_action_1_split
I0928 00:15:06.443832 29269 net.cpp:120] Top shape: 70 (70)
I0928 00:15:06.443837 29269 net.cpp:120] Top shape: 70 (70)
I0928 00:15:06.443840 29269 net.cpp:126] Memory required for data: 43285200
I0928 00:15:06.443845 29269 layer_factory.hpp:74] Creating layer conv1_action
I0928 00:15:06.443861 29269 net.cpp:84] Creating Layer conv1_action
I0928 00:15:06.443867 29269 net.cpp:384] conv1_action <- data_action
I0928 00:15:06.443879 29269 net.cpp:342] conv1_action -> conv1_action
I0928 00:15:06.443893 29269 net.cpp:113] Setting up conv1_action
I0928 00:15:06.446399 29269 net.cpp:120] Top shape: 70 96 55 55 (20328000)
I0928 00:15:06.446406 29269 net.cpp:126] Memory required for data: 124597200
I0928 00:15:06.446432 29269 layer_factory.hpp:74] Creating layer relu1_action
I0928 00:15:06.446447 29269 net.cpp:84] Creating Layer relu1_action
I0928 00:15:06.446452 29269 net.cpp:384] relu1_action <- conv1_action
I0928 00:15:06.446472 29269 net.cpp:331] relu1_action -> conv1_action (in-place)
I0928 00:15:06.446480 29269 net.cpp:113] Setting up relu1_action
I0928 00:15:06.446487 29269 net.cpp:120] Top shape: 70 96 55 55 (20328000)
I0928 00:15:06.446491 29269 net.cpp:126] Memory required for data: 205909200
I0928 00:15:06.446494 29269 layer_factory.hpp:74] Creating layer pool1_action
I0928 00:15:06.446512 29269 net.cpp:84] Creating Layer pool1_action
I0928 00:15:06.446517 29269 net.cpp:384] pool1_action <- conv1_action
I0928 00:15:06.446528 29269 net.cpp:342] pool1_action -> pool1_action
I0928 00:15:06.446539 29269 net.cpp:113] Setting up pool1_action
I0928 00:15:06.446560 29269 net.cpp:120] Top shape: 70 96 27 27 (4898880)
I0928 00:15:06.446575 29269 net.cpp:126] Memory required for data: 225504720
I0928 00:15:06.446579 29269 layer_factory.hpp:74] Creating layer norm1_action
I0928 00:15:06.446601 29269 net.cpp:84] Creating Layer norm1_action
I0928 00:15:06.446606 29269 net.cpp:384] norm1_action <- pool1_action
I0928 00:15:06.446616 29269 net.cpp:342] norm1_action -> norm1_action
I0928 00:15:06.446627 29269 net.cpp:113] Setting up norm1_action
I0928 00:15:06.446640 29269 net.cpp:120] Top shape: 70 96 27 27 (4898880)
I0928 00:15:06.446643 29269 net.cpp:126] Memory required for data: 245100240
I0928 00:15:06.446647 29269 layer_factory.hpp:74] Creating layer conv2_action
I0928 00:15:06.446658 29269 net.cpp:84] Creating Layer conv2_action
I0928 00:15:06.446663 29269 net.cpp:384] conv2_action <- norm1_action
I0928 00:15:06.446681 29269 net.cpp:342] conv2_action -> conv2_action
I0928 00:15:06.446698 29269 net.cpp:113] Setting up conv2_action
I0928 00:15:06.467993 29269 net.cpp:120] Top shape: 70 256 27 27 (13063680)
I0928 00:15:06.468015 29269 net.cpp:126] Memory required for data: 297354960
I0928 00:15:06.468041 29269 layer_factory.hpp:74] Creating layer relu2_action
I0928 00:15:06.468060 29269 net.cpp:84] Creating Layer relu2_action
I0928 00:15:06.468066 29269 net.cpp:384] relu2_action <- conv2_action
I0928 00:15:06.468081 29269 net.cpp:331] relu2_action -> conv2_action (in-place)
I0928 00:15:06.468091 29269 net.cpp:113] Setting up relu2_action
I0928 00:15:06.468098 29269 net.cpp:120] Top shape: 70 256 27 27 (13063680)
I0928 00:15:06.468101 29269 net.cpp:126] Memory required for data: 349609680
I0928 00:15:06.468106 29269 layer_factory.hpp:74] Creating layer pool2_action
I0928 00:15:06.468121 29269 net.cpp:84] Creating Layer pool2_action
I0928 00:15:06.468124 29269 net.cpp:384] pool2_action <- conv2_action
I0928 00:15:06.468134 29269 net.cpp:342] pool2_action -> pool2_action
I0928 00:15:06.468147 29269 net.cpp:113] Setting up pool2_action
I0928 00:15:06.468163 29269 net.cpp:120] Top shape: 70 256 13 13 (3028480)
I0928 00:15:06.468165 29269 net.cpp:126] Memory required for data: 361723600
I0928 00:15:06.468169 29269 layer_factory.hpp:74] Creating layer norm2_action
I0928 00:15:06.468180 29269 net.cpp:84] Creating Layer norm2_action
I0928 00:15:06.468185 29269 net.cpp:384] norm2_action <- pool2_action
I0928 00:15:06.468195 29269 net.cpp:342] norm2_action -> norm2_action
I0928 00:15:06.468204 29269 net.cpp:113] Setting up norm2_action
I0928 00:15:06.468215 29269 net.cpp:120] Top shape: 70 256 13 13 (3028480)
I0928 00:15:06.468219 29269 net.cpp:126] Memory required for data: 373837520
I0928 00:15:06.468222 29269 layer_factory.hpp:74] Creating layer conv3_action
I0928 00:15:06.468237 29269 net.cpp:84] Creating Layer conv3_action
I0928 00:15:06.468241 29269 net.cpp:384] conv3_action <- norm2_action
I0928 00:15:06.468253 29269 net.cpp:342] conv3_action -> conv3_action
I0928 00:15:06.468263 29269 net.cpp:113] Setting up conv3_action
I0928 00:15:06.529317 29269 net.cpp:120] Top shape: 70 384 13 13 (4542720)
I0928 00:15:06.529340 29269 net.cpp:126] Memory required for data: 392008400
I0928 00:15:06.529366 29269 layer_factory.hpp:74] Creating layer relu3_action
I0928 00:15:06.529383 29269 net.cpp:84] Creating Layer relu3_action
I0928 00:15:06.529389 29269 net.cpp:384] relu3_action <- conv3_action
I0928 00:15:06.529403 29269 net.cpp:331] relu3_action -> conv3_action (in-place)
I0928 00:15:06.529413 29269 net.cpp:113] Setting up relu3_action
I0928 00:15:06.529420 29269 net.cpp:120] Top shape: 70 384 13 13 (4542720)
I0928 00:15:06.529423 29269 net.cpp:126] Memory required for data: 410179280
I0928 00:15:06.529428 29269 layer_factory.hpp:74] Creating layer conv4_action
I0928 00:15:06.529443 29269 net.cpp:84] Creating Layer conv4_action
I0928 00:15:06.529448 29269 net.cpp:384] conv4_action <- conv3_action
I0928 00:15:06.529460 29269 net.cpp:342] conv4_action -> conv4_action
I0928 00:15:06.529471 29269 net.cpp:113] Setting up conv4_action
I0928 00:15:06.574837 29269 net.cpp:120] Top shape: 70 384 13 13 (4542720)
I0928 00:15:06.574846 29269 net.cpp:126] Memory required for data: 428350160
I0928 00:15:06.574856 29269 layer_factory.hpp:74] Creating layer relu4_action
I0928 00:15:06.574867 29269 net.cpp:84] Creating Layer relu4_action
I0928 00:15:06.574872 29269 net.cpp:384] relu4_action <- conv4_action
I0928 00:15:06.574883 29269 net.cpp:331] relu4_action -> conv4_action (in-place)
I0928 00:15:06.574892 29269 net.cpp:113] Setting up relu4_action
I0928 00:15:06.574898 29269 net.cpp:120] Top shape: 70 384 13 13 (4542720)
I0928 00:15:06.574900 29269 net.cpp:126] Memory required for data: 446521040
I0928 00:15:06.574904 29269 layer_factory.hpp:74] Creating layer conv5_action
I0928 00:15:06.574915 29269 net.cpp:84] Creating Layer conv5_action
I0928 00:15:06.574920 29269 net.cpp:384] conv5_action <- conv4_action
I0928 00:15:06.574934 29269 net.cpp:342] conv5_action -> conv5_action
I0928 00:15:06.574950 29269 net.cpp:113] Setting up conv5_action
I0928 00:15:06.605296 29269 net.cpp:120] Top shape: 70 256 13 13 (3028480)
I0928 00:15:06.605304 29269 net.cpp:126] Memory required for data: 458634960
I0928 00:15:06.605319 29269 layer_factory.hpp:74] Creating layer relu5_action
I0928 00:15:06.605329 29269 net.cpp:84] Creating Layer relu5_action
I0928 00:15:06.605334 29269 net.cpp:384] relu5_action <- conv5_action
I0928 00:15:06.605345 29269 net.cpp:331] relu5_action -> conv5_action (in-place)
I0928 00:15:06.605353 29269 net.cpp:113] Setting up relu5_action
I0928 00:15:06.605360 29269 net.cpp:120] Top shape: 70 256 13 13 (3028480)
I0928 00:15:06.605362 29269 net.cpp:126] Memory required for data: 470748880
I0928 00:15:06.605366 29269 layer_factory.hpp:74] Creating layer pool5_action
I0928 00:15:06.605381 29269 net.cpp:84] Creating Layer pool5_action
I0928 00:15:06.605386 29269 net.cpp:384] pool5_action <- conv5_action
I0928 00:15:06.605396 29269 net.cpp:342] pool5_action -> pool5_action
I0928 00:15:06.605406 29269 net.cpp:113] Setting up pool5_action
I0928 00:15:06.605419 29269 net.cpp:120] Top shape: 70 256 6 6 (645120)
I0928 00:15:06.605423 29269 net.cpp:126] Memory required for data: 473329360
I0928 00:15:06.605427 29269 layer_factory.hpp:74] Creating layer fc6_action
I0928 00:15:06.605443 29269 net.cpp:84] Creating Layer fc6_action
I0928 00:15:06.605448 29269 net.cpp:384] fc6_action <- pool5_action
I0928 00:15:06.605459 29269 net.cpp:342] fc6_action -> fc6_action
I0928 00:15:06.605471 29269 net.cpp:113] Setting up fc6_action
I0928 00:15:09.201021 29269 net.cpp:120] Top shape: 70 4096 (286720)
I0928 00:15:09.201047 29269 net.cpp:126] Memory required for data: 474476240
I0928 00:15:09.201066 29269 layer_factory.hpp:74] Creating layer relu6_action
I0928 00:15:09.201088 29269 net.cpp:84] Creating Layer relu6_action
I0928 00:15:09.201095 29269 net.cpp:384] relu6_action <- fc6_action
I0928 00:15:09.201112 29269 net.cpp:331] relu6_action -> fc6_action (in-place)
I0928 00:15:09.201123 29269 net.cpp:113] Setting up relu6_action
I0928 00:15:09.201129 29269 net.cpp:120] Top shape: 70 4096 (286720)
I0928 00:15:09.201133 29269 net.cpp:126] Memory required for data: 475623120
I0928 00:15:09.201136 29269 layer_factory.hpp:74] Creating layer drop6_action
I0928 00:15:09.201156 29269 net.cpp:84] Creating Layer drop6_action
I0928 00:15:09.201161 29269 net.cpp:384] drop6_action <- fc6_action
I0928 00:15:09.201170 29269 net.cpp:331] drop6_action -> fc6_action (in-place)
I0928 00:15:09.201179 29269 net.cpp:113] Setting up drop6_action
I0928 00:15:09.201191 29269 net.cpp:120] Top shape: 70 4096 (286720)
I0928 00:15:09.201195 29269 net.cpp:126] Memory required for data: 476770000
I0928 00:15:09.201200 29269 layer_factory.hpp:74] Creating layer fc7_action
I0928 00:15:09.201213 29269 net.cpp:84] Creating Layer fc7_action
I0928 00:15:09.201217 29269 net.cpp:384] fc7_action <- fc6_action
I0928 00:15:09.201233 29269 net.cpp:342] fc7_action -> fc7_action
I0928 00:15:09.201244 29269 net.cpp:113] Setting up fc7_action
I0928 00:15:10.354979 29269 net.cpp:120] Top shape: 70 4096 (286720)
I0928 00:15:10.355002 29269 net.cpp:126] Memory required for data: 477916880
I0928 00:15:10.355025 29269 layer_factory.hpp:74] Creating layer relu7_action
I0928 00:15:10.355047 29269 net.cpp:84] Creating Layer relu7_action
I0928 00:15:10.355056 29269 net.cpp:384] relu7_action <- fc7_action
I0928 00:15:10.355073 29269 net.cpp:331] relu7_action -> fc7_action (in-place)
I0928 00:15:10.355085 29269 net.cpp:113] Setting up relu7_action
I0928 00:15:10.355093 29269 net.cpp:120] Top shape: 70 4096 (286720)
I0928 00:15:10.355096 29269 net.cpp:126] Memory required for data: 479063760
I0928 00:15:10.355100 29269 layer_factory.hpp:74] Creating layer drop7_action
I0928 00:15:10.355110 29269 net.cpp:84] Creating Layer drop7_action
I0928 00:15:10.355115 29269 net.cpp:384] drop7_action <- fc7_action
I0928 00:15:10.355125 29269 net.cpp:331] drop7_action -> fc7_action (in-place)
I0928 00:15:10.355134 29269 net.cpp:113] Setting up drop7_action
I0928 00:15:10.355152 29269 net.cpp:120] Top shape: 70 4096 (286720)
I0928 00:15:10.355164 29269 net.cpp:126] Memory required for data: 480210640
I0928 00:15:10.355167 29269 layer_factory.hpp:74] Creating layer fc8_CAD_action
I0928 00:15:10.355182 29269 net.cpp:84] Creating Layer fc8_CAD_action
I0928 00:15:10.355187 29269 net.cpp:384] fc8_CAD_action <- fc7_action
I0928 00:15:10.355200 29269 net.cpp:342] fc8_CAD_action -> fc8_CAD_action
I0928 00:15:10.355216 29269 net.cpp:113] Setting up fc8_CAD_action
I0928 00:15:10.357220 29269 net.cpp:120] Top shape: 70 7 (490)
I0928 00:15:10.357226 29269 net.cpp:126] Memory required for data: 480212600
I0928 00:15:10.357235 29269 layer_factory.hpp:74] Creating layer fc8_CAD_action_fc8_CAD_action_0_split
I0928 00:15:10.357245 29269 net.cpp:84] Creating Layer fc8_CAD_action_fc8_CAD_action_0_split
I0928 00:15:10.357250 29269 net.cpp:384] fc8_CAD_action_fc8_CAD_action_0_split <- fc8_CAD_action
I0928 00:15:10.357260 29269 net.cpp:342] fc8_CAD_action_fc8_CAD_action_0_split -> fc8_CAD_action_fc8_CAD_action_0_split_0
I0928 00:15:10.357272 29269 net.cpp:342] fc8_CAD_action_fc8_CAD_action_0_split -> fc8_CAD_action_fc8_CAD_action_0_split_1
I0928 00:15:10.357280 29269 net.cpp:113] Setting up fc8_CAD_action_fc8_CAD_action_0_split
I0928 00:15:10.357290 29269 net.cpp:120] Top shape: 70 7 (490)
I0928 00:15:10.357293 29269 net.cpp:120] Top shape: 70 7 (490)
I0928 00:15:10.357296 29269 net.cpp:126] Memory required for data: 480216520
I0928 00:15:10.357300 29269 layer_factory.hpp:74] Creating layer data_frame
I0928 00:15:10.357316 29269 net.cpp:84] Creating Layer data_frame
I0928 00:15:10.357324 29269 net.cpp:342] data_frame -> data_frame
I0928 00:15:10.357336 29269 net.cpp:342] data_frame -> label_frame
I0928 00:15:10.357345 29269 net.cpp:113] Setting up data_frame
I0928 00:15:10.357393 29269 db.cpp:34] Opened lmdb /media/storage/zhiweid/CollectiveActivityDataset/databases/CAD_frame_train_lmdb_0903
I0928 00:15:10.357569 29269 data_layer.cpp:67] output data size: 5,3,227,227
I0928 00:15:10.357579 29269 data_transformer.cpp:22] Loading mean file from: imagenet_mean.binaryproto
I0928 00:15:10.363443 29269 base_data_layer.cpp:43] Initializing prefetch
I0928 00:15:10.363481 29269 base_data_layer.cpp:45] Prefetch initialized.
I0928 00:15:10.363489 29269 net.cpp:120] Top shape: 5 3 227 227 (772935)
I0928 00:15:10.363494 29269 net.cpp:120] Top shape: 5 (5)
I0928 00:15:10.363497 29269 net.cpp:126] Memory required for data: 483308280
I0928 00:15:10.363502 29269 layer_factory.hpp:74] Creating layer conv1_frame
I0928 00:15:10.363518 29269 net.cpp:84] Creating Layer conv1_frame
I0928 00:15:10.363524 29269 net.cpp:384] conv1_frame <- data_frame
I0928 00:15:10.363539 29269 net.cpp:342] conv1_frame -> conv1_frame
I0928 00:15:10.363551 29269 net.cpp:113] Setting up conv1_frame
I0928 00:15:10.365975 29269 net.cpp:120] Top shape: 5 96 55 55 (1452000)
I0928 00:15:10.365984 29269 net.cpp:126] Memory required for data: 489116280
I0928 00:15:10.366000 29269 layer_factory.hpp:74] Creating layer relu1_frame
I0928 00:15:10.366013 29269 net.cpp:84] Creating Layer relu1_frame
I0928 00:15:10.366016 29269 net.cpp:384] relu1_frame <- conv1_frame
I0928 00:15:10.366027 29269 net.cpp:331] relu1_frame -> conv1_frame (in-place)
I0928 00:15:10.366035 29269 net.cpp:113] Setting up relu1_frame
I0928 00:15:10.366041 29269 net.cpp:120] Top shape: 5 96 55 55 (1452000)
I0928 00:15:10.366044 29269 net.cpp:126] Memory required for data: 494924280
I0928 00:15:10.366047 29269 layer_factory.hpp:74] Creating layer pool1_frame
I0928 00:15:10.366058 29269 net.cpp:84] Creating Layer pool1_frame
I0928 00:15:10.366062 29269 net.cpp:384] pool1_frame <- conv1_frame
I0928 00:15:10.366072 29269 net.cpp:342] pool1_frame -> pool1_frame
I0928 00:15:10.366082 29269 net.cpp:113] Setting up pool1_frame
I0928 00:15:10.366096 29269 net.cpp:120] Top shape: 5 96 27 27 (349920)
I0928 00:15:10.366099 29269 net.cpp:126] Memory required for data: 496323960
I0928 00:15:10.366103 29269 layer_factory.hpp:74] Creating layer norm1_frame
I0928 00:15:10.366113 29269 net.cpp:84] Creating Layer norm1_frame
I0928 00:15:10.366123 29269 net.cpp:384] norm1_frame <- pool1_frame
I0928 00:15:10.366142 29269 net.cpp:342] norm1_frame -> norm1_frame
I0928 00:15:10.366152 29269 net.cpp:113] Setting up norm1_frame
I0928 00:15:10.366163 29269 net.cpp:120] Top shape: 5 96 27 27 (349920)
I0928 00:15:10.366165 29269 net.cpp:126] Memory required for data: 497723640
I0928 00:15:10.366169 29269 layer_factory.hpp:74] Creating layer conv2_frame
I0928 00:15:10.366181 29269 net.cpp:84] Creating Layer conv2_frame
I0928 00:15:10.366186 29269 net.cpp:384] conv2_frame <- norm1_frame
I0928 00:15:10.366197 29269 net.cpp:342] conv2_frame -> conv2_frame
I0928 00:15:10.366207 29269 net.cpp:113] Setting up conv2_frame
I0928 00:15:10.387197 29269 net.cpp:120] Top shape: 5 256 27 27 (933120)
I0928 00:15:10.387205 29269 net.cpp:126] Memory required for data: 501456120
I0928 00:15:10.387215 29269 layer_factory.hpp:74] Creating layer relu2_frame
I0928 00:15:10.387226 29269 net.cpp:84] Creating Layer relu2_frame
I0928 00:15:10.387231 29269 net.cpp:384] relu2_frame <- conv2_frame
I0928 00:15:10.387243 29269 net.cpp:331] relu2_frame -> conv2_frame (in-place)
I0928 00:15:10.387253 29269 net.cpp:113] Setting up relu2_frame
I0928 00:15:10.387259 29269 net.cpp:120] Top shape: 5 256 27 27 (933120)
I0928 00:15:10.387260 29269 net.cpp:126] Memory required for data: 505188600
I0928 00:15:10.387264 29269 layer_factory.hpp:74] Creating layer pool2_frame
I0928 00:15:10.387281 29269 net.cpp:84] Creating Layer pool2_frame
I0928 00:15:10.387286 29269 net.cpp:384] pool2_frame <- conv2_frame
I0928 00:15:10.387296 29269 net.cpp:342] pool2_frame -> pool2_frame
I0928 00:15:10.387305 29269 net.cpp:113] Setting up pool2_frame
I0928 00:15:10.387318 29269 net.cpp:120] Top shape: 5 256 13 13 (216320)
I0928 00:15:10.387321 29269 net.cpp:126] Memory required for data: 506053880
I0928 00:15:10.387326 29269 layer_factory.hpp:74] Creating layer norm2_frame
I0928 00:15:10.387336 29269 net.cpp:84] Creating Layer norm2_frame
I0928 00:15:10.387341 29269 net.cpp:384] norm2_frame <- pool2_frame
I0928 00:15:10.387351 29269 net.cpp:342] norm2_frame -> norm2_frame
I0928 00:15:10.387359 29269 net.cpp:113] Setting up norm2_frame
I0928 00:15:10.387369 29269 net.cpp:120] Top shape: 5 256 13 13 (216320)
I0928 00:15:10.387372 29269 net.cpp:126] Memory required for data: 506919160
I0928 00:15:10.387377 29269 layer_factory.hpp:74] Creating layer conv3_frame
I0928 00:15:10.387389 29269 net.cpp:84] Creating Layer conv3_frame
I0928 00:15:10.387394 29269 net.cpp:384] conv3_frame <- norm2_frame
I0928 00:15:10.387406 29269 net.cpp:342] conv3_frame -> conv3_frame
I0928 00:15:10.387418 29269 net.cpp:113] Setting up conv3_frame
I0928 00:15:10.448359 29269 net.cpp:120] Top shape: 5 384 13 13 (324480)
I0928 00:15:10.448369 29269 net.cpp:126] Memory required for data: 508217080
I0928 00:15:10.448380 29269 layer_factory.hpp:74] Creating layer relu3_frame
I0928 00:15:10.448392 29269 net.cpp:84] Creating Layer relu3_frame
I0928 00:15:10.448397 29269 net.cpp:384] relu3_frame <- conv3_frame
I0928 00:15:10.448410 29269 net.cpp:331] relu3_frame -> conv3_frame (in-place)
I0928 00:15:10.448418 29269 net.cpp:113] Setting up relu3_frame
I0928 00:15:10.448424 29269 net.cpp:120] Top shape: 5 384 13 13 (324480)
I0928 00:15:10.448427 29269 net.cpp:126] Memory required for data: 509515000
I0928 00:15:10.448431 29269 layer_factory.hpp:74] Creating layer conv4_frame
I0928 00:15:10.448442 29269 net.cpp:84] Creating Layer conv4_frame
I0928 00:15:10.448447 29269 net.cpp:384] conv4_frame <- conv3_frame
I0928 00:15:10.448460 29269 net.cpp:342] conv4_frame -> conv4_frame
I0928 00:15:10.448472 29269 net.cpp:113] Setting up conv4_frame
I0928 00:15:10.494073 29269 net.cpp:120] Top shape: 5 384 13 13 (324480)
I0928 00:15:10.494084 29269 net.cpp:126] Memory required for data: 510812920
I0928 00:15:10.494096 29269 layer_factory.hpp:74] Creating layer relu4_frame
I0928 00:15:10.494105 29269 net.cpp:84] Creating Layer relu4_frame
I0928 00:15:10.494112 29269 net.cpp:384] relu4_frame <- conv4_frame
I0928 00:15:10.494122 29269 net.cpp:331] relu4_frame -> conv4_frame (in-place)
I0928 00:15:10.494138 29269 net.cpp:113] Setting up relu4_frame
I0928 00:15:10.494151 29269 net.cpp:120] Top shape: 5 384 13 13 (324480)
I0928 00:15:10.494154 29269 net.cpp:126] Memory required for data: 512110840
I0928 00:15:10.494158 29269 layer_factory.hpp:74] Creating layer conv5_frame
I0928 00:15:10.494171 29269 net.cpp:84] Creating Layer conv5_frame
I0928 00:15:10.494176 29269 net.cpp:384] conv5_frame <- conv4_frame
I0928 00:15:10.494189 29269 net.cpp:342] conv5_frame -> conv5_frame
I0928 00:15:10.494199 29269 net.cpp:113] Setting up conv5_frame
I0928 00:15:10.524540 29269 net.cpp:120] Top shape: 5 256 13 13 (216320)
I0928 00:15:10.524549 29269 net.cpp:126] Memory required for data: 512976120
I0928 00:15:10.524559 29269 layer_factory.hpp:74] Creating layer relu5_frame
I0928 00:15:10.524569 29269 net.cpp:84] Creating Layer relu5_frame
I0928 00:15:10.524574 29269 net.cpp:384] relu5_frame <- conv5_frame
I0928 00:15:10.524583 29269 net.cpp:331] relu5_frame -> conv5_frame (in-place)
I0928 00:15:10.524591 29269 net.cpp:113] Setting up relu5_frame
I0928 00:15:10.524596 29269 net.cpp:120] Top shape: 5 256 13 13 (216320)
I0928 00:15:10.524600 29269 net.cpp:126] Memory required for data: 513841400
I0928 00:15:10.524603 29269 layer_factory.hpp:74] Creating layer pool5_frame
I0928 00:15:10.524616 29269 net.cpp:84] Creating Layer pool5_frame
I0928 00:15:10.524619 29269 net.cpp:384] pool5_frame <- conv5_frame
I0928 00:15:10.524629 29269 net.cpp:342] pool5_frame -> pool5_frame
I0928 00:15:10.524639 29269 net.cpp:113] Setting up pool5_frame
I0928 00:15:10.524652 29269 net.cpp:120] Top shape: 5 256 6 6 (46080)
I0928 00:15:10.524657 29269 net.cpp:126] Memory required for data: 514025720
I0928 00:15:10.524659 29269 layer_factory.hpp:74] Creating layer fc6_frame
I0928 00:15:10.524672 29269 net.cpp:84] Creating Layer fc6_frame
I0928 00:15:10.524677 29269 net.cpp:384] fc6_frame <- pool5_frame
I0928 00:15:10.524689 29269 net.cpp:342] fc6_frame -> fc6_frame
I0928 00:15:10.524700 29269 net.cpp:113] Setting up fc6_frame
I0928 00:15:13.113680 29269 net.cpp:120] Top shape: 5 4096 (20480)
I0928 00:15:13.113703 29269 net.cpp:126] Memory required for data: 514107640
I0928 00:15:13.113724 29269 layer_factory.hpp:74] Creating layer relu6_frame
I0928 00:15:13.113745 29269 net.cpp:84] Creating Layer relu6_frame
I0928 00:15:13.113754 29269 net.cpp:384] relu6_frame <- fc6_frame
I0928 00:15:13.113771 29269 net.cpp:331] relu6_frame -> fc6_frame (in-place)
I0928 00:15:13.113783 29269 net.cpp:113] Setting up relu6_frame
I0928 00:15:13.113790 29269 net.cpp:120] Top shape: 5 4096 (20480)
I0928 00:15:13.113793 29269 net.cpp:126] Memory required for data: 514189560
I0928 00:15:13.113797 29269 layer_factory.hpp:74] Creating layer drop6_frame
I0928 00:15:13.113807 29269 net.cpp:84] Creating Layer drop6_frame
I0928 00:15:13.113811 29269 net.cpp:384] drop6_frame <- fc6_frame
I0928 00:15:13.113822 29269 net.cpp:331] drop6_frame -> fc6_frame (in-place)
I0928 00:15:13.113831 29269 net.cpp:113] Setting up drop6_frame
I0928 00:15:13.113842 29269 net.cpp:120] Top shape: 5 4096 (20480)
I0928 00:15:13.113844 29269 net.cpp:126] Memory required for data: 514271480
I0928 00:15:13.113848 29269 layer_factory.hpp:74] Creating layer fc7_frame
I0928 00:15:13.113862 29269 net.cpp:84] Creating Layer fc7_frame
I0928 00:15:13.113867 29269 net.cpp:384] fc7_frame <- fc6_frame
I0928 00:15:13.113888 29269 net.cpp:342] fc7_frame -> fc7_frame
I0928 00:15:13.113909 29269 net.cpp:113] Setting up fc7_frame
I0928 00:15:14.271494 29269 net.cpp:120] Top shape: 5 4096 (20480)
I0928 00:15:14.271519 29269 net.cpp:126] Memory required for data: 514353400
I0928 00:15:14.271559 29269 layer_factory.hpp:74] Creating layer relu7_frame
I0928 00:15:14.271672 29269 net.cpp:84] Creating Layer relu7_frame
I0928 00:15:14.271687 29269 net.cpp:384] relu7_frame <- fc7_frame
I0928 00:15:14.271708 29269 net.cpp:331] relu7_frame -> fc7_frame (in-place)
I0928 00:15:14.271720 29269 net.cpp:113] Setting up relu7_frame
I0928 00:15:14.271728 29269 net.cpp:120] Top shape: 5 4096 (20480)
I0928 00:15:14.271738 29269 net.cpp:126] Memory required for data: 514435320
I0928 00:15:14.271750 29269 layer_factory.hpp:74] Creating layer drop7_frame
I0928 00:15:14.271761 29269 net.cpp:84] Creating Layer drop7_frame
I0928 00:15:14.271766 29269 net.cpp:384] drop7_frame <- fc7_frame
I0928 00:15:14.271775 29269 net.cpp:331] drop7_frame -> fc7_frame (in-place)
I0928 00:15:14.271783 29269 net.cpp:113] Setting up drop7_frame
I0928 00:15:14.271795 29269 net.cpp:120] Top shape: 5 4096 (20480)
I0928 00:15:14.271798 29269 net.cpp:126] Memory required for data: 514517240
I0928 00:15:14.271802 29269 layer_factory.hpp:74] Creating layer fc8_CAD_frame
I0928 00:15:14.271816 29269 net.cpp:84] Creating Layer fc8_CAD_frame
I0928 00:15:14.271821 29269 net.cpp:384] fc8_CAD_frame <- fc7_frame
I0928 00:15:14.271844 29269 net.cpp:342] fc8_CAD_frame -> fc8_CAD_frame
I0928 00:15:14.271858 29269 net.cpp:113] Setting up fc8_CAD_frame
I0928 00:15:14.273370 29269 net.cpp:120] Top shape: 5 5 (25)
I0928 00:15:14.273376 29269 net.cpp:126] Memory required for data: 514517340
I0928 00:15:14.273386 29269 layer_factory.hpp:74] Creating layer prob_frame
I0928 00:15:14.273404 29269 net.cpp:84] Creating Layer prob_frame
I0928 00:15:14.273409 29269 net.cpp:384] prob_frame <- fc8_CAD_frame
I0928 00:15:14.273419 29269 net.cpp:342] prob_frame -> fc8_CAD_frame_prob
I0928 00:15:14.273429 29269 net.cpp:113] Setting up prob_frame
I0928 00:15:14.273442 29269 net.cpp:120] Top shape: 5 5 (25)
I0928 00:15:14.273447 29269 net.cpp:126] Memory required for data: 514517440
I0928 00:15:14.273450 29269 layer_factory.hpp:74] Creating layer prob_action
I0928 00:15:14.273459 29269 net.cpp:84] Creating Layer prob_action
I0928 00:15:14.273464 29269 net.cpp:384] prob_action <- fc8_CAD_action_fc8_CAD_action_0_split_0
I0928 00:15:14.273473 29269 net.cpp:342] prob_action -> fc8_CAD_prob
I0928 00:15:14.273484 29269 net.cpp:113] Setting up prob_action
I0928 00:15:14.273495 29269 net.cpp:120] Top shape: 70 7 (490)
I0928 00:15:14.273499 29269 net.cpp:126] Memory required for data: 514519400
I0928 00:15:14.273502 29269 layer_factory.hpp:74] Creating layer Data_arrange_layer_filter
I0928 00:15:14.518777 29269 net.cpp:84] Creating Layer Data_arrange_layer_filter
I0928 00:15:14.518815 29269 net.cpp:384] Data_arrange_layer_filter <- fc8_CAD_action_fc8_CAD_action_0_split_1
I0928 00:15:14.518839 29269 net.cpp:384] Data_arrange_layer_filter <- label_action_data_action_1_split_0
I0928 00:15:14.518853 29269 net.cpp:342] Data_arrange_layer_filter -> fc9_filtered
I0928 00:15:14.518868 29269 net.cpp:113] Setting up Data_arrange_layer_filter
I0928 00:15:14.518970 29269 net.cpp:120] Top shape: 5 98 (490)
I0928 00:15:14.518976 29269 net.cpp:126] Memory required for data: 514521360
I0928 00:15:14.518982 29269 layer_factory.hpp:74] Creating layer concatenation_s_a_p
I0928 00:15:14.519000 29269 net.cpp:84] Creating Layer concatenation_s_a_p
I0928 00:15:14.519006 29269 net.cpp:384] concatenation_s_a_p <- fc8_CAD_frame_prob
I0928 00:15:14.519016 29269 net.cpp:384] concatenation_s_a_p <- fc9_filtered
I0928 00:15:14.519026 29269 net.cpp:342] concatenation_s_a_p -> concat_all
I0928 00:15:14.519037 29269 net.cpp:113] Setting up concatenation_s_a_p
I0928 00:15:14.519049 29269 net.cpp:120] Top shape: 5 103 (515)
I0928 00:15:14.519052 29269 net.cpp:126] Memory required for data: 514523420
I0928 00:15:14.519057 29269 layer_factory.hpp:74] Creating layer simplified_message_in
I0928 00:15:14.520660 29269 net.cpp:84] Creating Layer simplified_message_in
I0928 00:15:14.520671 29269 net.cpp:384] simplified_message_in <- concat_all
I0928 00:15:14.520683 29269 net.cpp:384] simplified_message_in <- label_action_data_action_1_split_1
I0928 00:15:14.520694 29269 net.cpp:342] simplified_message_in -> a2a
I0928 00:15:14.520705 29269 net.cpp:342] simplified_message_in -> s2a
I0928 00:15:14.520716 29269 net.cpp:342] simplified_message_in -> a2s
I0928 00:15:14.520725 29269 net.cpp:113] Setting up simplified_message_in
I0928 00:15:14.521196 29269 net.cpp:120] Top shape: 0 7 (0)
I0928 00:15:14.521205 29269 net.cpp:120] Top shape: 0 7 (0)
I0928 00:15:14.521214 29269 net.cpp:120] Top shape: 0 5 (0)
I0928 00:15:14.521224 29269 net.cpp:126] Memory required for data: 514523420
I0928 00:15:14.521230 29269 net.cpp:169] simplified_message_in does not need backward computation.
I0928 00:15:14.521234 29269 net.cpp:169] concatenation_s_a_p does not need backward computation.
I0928 00:15:14.521236 29269 net.cpp:169] Data_arrange_layer_filter does not need backward computation.
I0928 00:15:14.521239 29269 net.cpp:169] prob_action does not need backward computation.
I0928 00:15:14.521242 29269 net.cpp:169] prob_frame does not need backward computation.
I0928 00:15:14.521245 29269 net.cpp:169] fc8_CAD_frame does not need backward computation.
I0928 00:15:14.521248 29269 net.cpp:169] drop7_frame does not need backward computation.
I0928 00:15:14.521250 29269 net.cpp:169] relu7_frame does not need backward computation.
I0928 00:15:14.521253 29269 net.cpp:169] fc7_frame does not need backward computation.
I0928 00:15:14.521256 29269 net.cpp:169] drop6_frame does not need backward computation.
I0928 00:15:14.521260 29269 net.cpp:169] relu6_frame does not need backward computation.
I0928 00:15:14.521262 29269 net.cpp:169] fc6_frame does not need backward computation.
I0928 00:15:14.521265 29269 net.cpp:169] pool5_frame does not need backward computation.
I0928 00:15:14.521267 29269 net.cpp:169] relu5_frame does not need backward computation.
I0928 00:15:14.521270 29269 net.cpp:169] conv5_frame does not need backward computation.
I0928 00:15:14.521273 29269 net.cpp:169] relu4_frame does not need backward computation.
I0928 00:15:14.521275 29269 net.cpp:169] conv4_frame does not need backward computation.
I0928 00:15:14.521278 29269 net.cpp:169] relu3_frame does not need backward computation.
I0928 00:15:14.521281 29269 net.cpp:169] conv3_frame does not need backward computation.
I0928 00:15:14.521284 29269 net.cpp:169] norm2_frame does not need backward computation.
I0928 00:15:14.521286 29269 net.cpp:169] pool2_frame does not need backward computation.
I0928 00:15:14.521289 29269 net.cpp:169] relu2_frame does not need backward computation.
I0928 00:15:14.521292 29269 net.cpp:169] conv2_frame does not need backward computation.
I0928 00:15:14.521296 29269 net.cpp:169] norm1_frame does not need backward computation.
I0928 00:15:14.521297 29269 net.cpp:169] pool1_frame does not need backward computation.
I0928 00:15:14.521301 29269 net.cpp:169] relu1_frame does not need backward computation.
I0928 00:15:14.521303 29269 net.cpp:169] conv1_frame does not need backward computation.
I0928 00:15:14.521306 29269 net.cpp:169] data_frame does not need backward computation.
I0928 00:15:14.521308 29269 net.cpp:169] fc8_CAD_action_fc8_CAD_action_0_split does not need backward computation.
I0928 00:15:14.521311 29269 net.cpp:169] fc8_CAD_action does not need backward computation.
I0928 00:15:14.521314 29269 net.cpp:169] drop7_action does not need backward computation.
I0928 00:15:14.521317 29269 net.cpp:169] relu7_action does not need backward computation.
I0928 00:15:14.521320 29269 net.cpp:169] fc7_action does not need backward computation.
I0928 00:15:14.521322 29269 net.cpp:169] drop6_action does not need backward computation.
I0928 00:15:14.521325 29269 net.cpp:169] relu6_action does not need backward computation.
I0928 00:15:14.521328 29269 net.cpp:169] fc6_action does not need backward computation.
I0928 00:15:14.521330 29269 net.cpp:169] pool5_action does not need backward computation.
I0928 00:15:14.521333 29269 net.cpp:169] relu5_action does not need backward computation.
I0928 00:15:14.521337 29269 net.cpp:169] conv5_action does not need backward computation.
I0928 00:15:14.521339 29269 net.cpp:169] relu4_action does not need backward computation.
I0928 00:15:14.521342 29269 net.cpp:169] conv4_action does not need backward computation.
I0928 00:15:14.521344 29269 net.cpp:169] relu3_action does not need backward computation.
I0928 00:15:14.521347 29269 net.cpp:169] conv3_action does not need backward computation.
I0928 00:15:14.521350 29269 net.cpp:169] norm2_action does not need backward computation.
I0928 00:15:14.521354 29269 net.cpp:169] pool2_action does not need backward computation.
I0928 00:15:14.521360 29269 net.cpp:169] relu2_action does not need backward computation.
I0928 00:15:14.521363 29269 net.cpp:169] conv2_action does not need backward computation.
I0928 00:15:14.521366 29269 net.cpp:169] norm1_action does not need backward computation.
I0928 00:15:14.521369 29269 net.cpp:169] pool1_action does not need backward computation.
I0928 00:15:14.521373 29269 net.cpp:169] relu1_action does not need backward computation.
I0928 00:15:14.521375 29269 net.cpp:169] conv1_action does not need backward computation.
I0928 00:15:14.521378 29269 net.cpp:169] label_action_data_action_1_split does not need backward computation.
I0928 00:15:14.521380 29269 net.cpp:169] data_action does not need backward computation.
I0928 00:15:14.521405 29269 net.cpp:208] This network produces output a2a
I0928 00:15:14.521412 29269 net.cpp:208] This network produces output a2s
I0928 00:15:14.521417 29269 net.cpp:208] This network produces output fc8_CAD_prob
I0928 00:15:14.521422 29269 net.cpp:208] This network produces output label_frame
I0928 00:15:14.521425 29269 net.cpp:208] This network produces output s2a
I0928 00:15:14.521473 29269 net.cpp:449] Collecting Learning Rate and Weight Decay.
I0928 00:15:14.521489 29269 net.cpp:221] Network initialization done.
I0928 00:15:14.521492 29269 net.cpp:222] Memory required for data: 514523420
I0928 00:15:14.522357 29269 solver.cpp:154] Creating test net (#0) specified by net file: prototxts/test_print_1.prototxt
I0928 00:15:14.522452 29269 net.cpp:261] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_action
I0928 00:15:14.522481 29269 net.cpp:261] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_frame
I0928 00:15:14.522713 29269 net.cpp:42] Initializing net from parameters: 
name: "CaffeNet"
force_backward: true
state {
  phase: TEST
}
layer {
  name: "data_action"
  type: "Data"
  top: "data_action"
  top: "label_action"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "imagenet_mean.binaryproto"
  }
  data_param {
    source: "/media/storage/zhiweid/CollectiveActivityDataset/databases/CAD_action_val_lmdb_0903"
    batch_size: 70
    backend: LMDB
  }
}
layer {
  name: "conv1_action"
  type: "Convolution"
  bottom: "data_action"
  top: "conv1_action"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_action"
  type: "ReLU"
  bottom: "conv1_action"
  top: "conv1_action"
}
layer {
  name: "pool1_action"
  type: "Pooling"
  bottom: "conv1_action"
  top: "pool1_action"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1_action"
  type: "LRN"
  bottom: "pool1_action"
  top: "norm1_action"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2_action"
  type: "Convolution"
  bottom: "norm1_action"
  top: "conv2_action"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2_action"
  type: "ReLU"
  bottom: "conv2_action"
  top: "conv2_action"
}
layer {
  name: "pool2_action"
  type: "Pooling"
  bottom: "conv2_action"
  top: "pool2_action"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2_action"
  type: "LRN"
  bottom: "pool2_action"
  top: "norm2_action"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3_action"
  type: "Convolution"
  bottom: "norm2_action"
  top: "conv3_action"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_action"
  type: "ReLU"
  bottom: "conv3_action"
  top: "conv3_action"
}
layer {
  name: "conv4_action"
  type: "Convolution"
  bottom: "conv3_action"
  top: "conv4_action"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4_action"
  type: "ReLU"
  bottom: "conv4_action"
  top: "conv4_action"
}
layer {
  name: "conv5_action"
  type: "Convolution"
  bottom: "conv4_action"
  top: "conv5_action"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5_action"
  type: "ReLU"
  bottom: "conv5_action"
  top: "conv5_action"
}
layer {
  name: "pool5_action"
  type: "Pooling"
  bottom: "conv5_action"
  top: "pool5_action"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6_action"
  type: "InnerProduct"
  bottom: "pool5_action"
  top: "fc6_action"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6_action"
  type: "ReLU"
  bottom: "fc6_action"
  top: "fc6_action"
}
layer {
  name: "drop6_action"
  type: "Dropout"
  bottom: "fc6_action"
  top: "fc6_action"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_action"
  type: "InnerProduct"
  bottom: "fc6_action"
  top: "fc7_action"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7_action"
  type: "ReLU"
  bottom: "fc7_action"
  top: "fc7_action"
}
layer {
  name: "drop7_action"
  type: "Dropout"
  bottom: "fc7_action"
  top: "fc7_action"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_CAD_action"
  type: "InnerProduct"
  bottom: "fc7_action"
  top: "fc8_CAD_action"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  inner_product_param {
    num_output: 7
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "data_frame"
  type: "Data"
  top: "data_frame"
  top: "label_frame"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "imagenet_mean.binaryproto"
  }
  data_param {
    source: "/media/storage/zhiweid/CollectiveActivityDataset/databases/CAD_frame_val_lmdb_0903"
    batch_size: 5
    backend: LMDB
  }
}
layer {
  name: "conv1_frame"
  type: "Convolution"
  bottom: "data_frame"
  top: "conv1_frame"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_frame"
  type: "ReLU"
  bottom: "conv1_frame"
  top: "conv1_frame"
}
layer {
  name: "pool1_frame"
  type: "Pooling"
  bottom: "conv1_frame"
  top: "pool1_frame"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1_frame"
  type: "LRN"
  bottom: "pool1_frame"
  top: "norm1_frame"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2_frame"
  type: "Convolution"
  bottom: "norm1_frame"
  top: "conv2_frame"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2_frame"
  type: "ReLU"
  bottom: "conv2_frame"
  top: "conv2_frame"
}
layer {
  name: "pool2_frame"
  type: "Pooling"
  bottom: "conv2_frame"
  top: "pool2_frame"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2_frame"
  type: "LRN"
  bottom: "pool2_frame"
  top: "norm2_frame"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3_frame"
  type: "Convolution"
  bottom: "norm2_frame"
  top: "conv3_frame"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_frame"
  type: "ReLU"
  bottom: "conv3_frame"
  top: "conv3_frame"
}
layer {
  name: "conv4_frame"
  type: "Convolution"
  bottom: "conv3_frame"
  top: "conv4_frame"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4_frame"
  type: "ReLU"
  bottom: "conv4_frame"
  top: "conv4_frame"
}
layer {
  name: "conv5_frame"
  type: "Convolution"
  bottom: "conv4_frame"
  top: "conv5_frame"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5_frame"
  type: "ReLU"
  bottom: "conv5_frame"
  top: "conv5_frame"
}
layer {
  name: "pool5_frame"
  type: "Pooling"
  bottom: "conv5_frame"
  top: "pool5_frame"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6_frame"
  type: "InnerProduct"
  bottom: "pool5_frame"
  top: "fc6_frame"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6_frame"
  type: "ReLU"
  bottom: "fc6_frame"
  top: "fc6_frame"
}
layer {
  name: "drop6_frame"
  type: "Dropout"
  bottom: "fc6_frame"
  top: "fc6_frame"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_frame"
  type: "InnerProduct"
  bottom: "fc6_frame"
  top: "fc7_frame"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7_frame"
  type: "ReLU"
  bottom: "fc7_frame"
  top: "fc7_frame"
}
layer {
  name: "drop7_frame"
  type: "Dropout"
  bottom: "fc7_frame"
  top: "fc7_frame"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_CAD_frame"
  type: "InnerProduct"
  bottom: "fc7_frame"
  top: "fc8_CAD_frame"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  inner_product_param {
    num_output: 5
    bias_term: true
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "prob_frame"
  type: "Softmax"
  bottom: "fc8_CAD_frame"
  top: "fc8_CAD_frame_prob"
}
layer {
  name: "prob_action"
  type: "Softmax"
  bottom: "fc8_CAD_action"
  top: "fc8_CAD_prob"
}
layer {
  name: "Data_arrange_layer_filter"
  type: "Python"
  bottom: "fc8_CAD_action"
  bottom: "label_action"
  top: "fc9_filtered"
  python_param {
    module: "Data_arrange"
    layer: "Data_Arrange_Layer"
  }
}
layer {
  name: "concatenation_s_a_p"
  type: "Concat"
  bottom: "fc8_CAD_frame_prob"
  bottom: "fc9_filtered"
  top: "concat_all"
  concat_param {
    concat_dim: 1
  }
}
layer {
  name: "simplified_message_in"
  type: "Python"
  bottom: "concat_all"
  bottom: "label_action"
  top: "a2a"
  top: "s2a"
  top: "a2s"
  python_param {
    module: "simplified_message_in"
    layer: "simplified_message_in"
  }
}
I0928 00:15:14.523000 29269 net.cpp:67] Memory required for data: 0
I0928 00:15:14.523057 29269 layer_factory.hpp:74] Creating layer data_action
I0928 00:15:14.523073 29269 net.cpp:84] Creating Layer data_action
I0928 00:15:14.523082 29269 net.cpp:342] data_action -> data_action
I0928 00:15:14.523097 29269 net.cpp:342] data_action -> label_action
I0928 00:15:14.523109 29269 net.cpp:113] Setting up data_action
I0928 00:15:14.523144 29269 db.cpp:34] Opened lmdb /media/storage/zhiweid/CollectiveActivityDataset/databases/CAD_action_val_lmdb_0903
I0928 00:15:14.523227 29269 data_layer.cpp:67] output data size: 70,3,227,227
I0928 00:15:14.523236 29269 data_transformer.cpp:22] Loading mean file from: imagenet_mean.binaryproto
I0928 00:15:14.533892 29269 base_data_layer.cpp:43] Initializing prefetch
I0928 00:15:14.533936 29269 base_data_layer.cpp:45] Prefetch initialized.
I0928 00:15:14.533959 29269 net.cpp:120] Top shape: 70 3 227 227 (10821090)
I0928 00:15:14.533965 29269 net.cpp:120] Top shape: 70 (70)
I0928 00:15:14.533977 29269 net.cpp:126] Memory required for data: 43284640
I0928 00:15:14.533989 29269 layer_factory.hpp:74] Creating layer label_action_data_action_1_split
I0928 00:15:14.534009 29269 net.cpp:84] Creating Layer label_action_data_action_1_split
I0928 00:15:14.534018 29269 net.cpp:384] label_action_data_action_1_split <- label_action
I0928 00:15:14.534034 29269 net.cpp:342] label_action_data_action_1_split -> label_action_data_action_1_split_0
I0928 00:15:14.534049 29269 net.cpp:342] label_action_data_action_1_split -> label_action_data_action_1_split_1
I0928 00:15:14.534059 29269 net.cpp:113] Setting up label_action_data_action_1_split
I0928 00:15:14.534070 29269 net.cpp:120] Top shape: 70 (70)
I0928 00:15:14.534075 29269 net.cpp:120] Top shape: 70 (70)
I0928 00:15:14.534077 29269 net.cpp:126] Memory required for data: 43285200
I0928 00:15:14.534081 29269 layer_factory.hpp:74] Creating layer conv1_action
I0928 00:15:14.534099 29269 net.cpp:84] Creating Layer conv1_action
I0928 00:15:14.534104 29269 net.cpp:384] conv1_action <- data_action
I0928 00:15:14.534117 29269 net.cpp:342] conv1_action -> conv1_action
I0928 00:15:14.534131 29269 net.cpp:113] Setting up conv1_action
I0928 00:15:14.536494 29269 net.cpp:120] Top shape: 70 96 55 55 (20328000)
I0928 00:15:14.536499 29269 net.cpp:126] Memory required for data: 124597200
I0928 00:15:14.536514 29269 layer_factory.hpp:74] Creating layer relu1_action
I0928 00:15:14.536525 29269 net.cpp:84] Creating Layer relu1_action
I0928 00:15:14.536530 29269 net.cpp:384] relu1_action <- conv1_action
I0928 00:15:14.536540 29269 net.cpp:331] relu1_action -> conv1_action (in-place)
I0928 00:15:14.536548 29269 net.cpp:113] Setting up relu1_action
I0928 00:15:14.536555 29269 net.cpp:120] Top shape: 70 96 55 55 (20328000)
I0928 00:15:14.536557 29269 net.cpp:126] Memory required for data: 205909200
I0928 00:15:14.536561 29269 layer_factory.hpp:74] Creating layer pool1_action
I0928 00:15:14.536574 29269 net.cpp:84] Creating Layer pool1_action
I0928 00:15:14.536579 29269 net.cpp:384] pool1_action <- conv1_action
I0928 00:15:14.536591 29269 net.cpp:342] pool1_action -> pool1_action
I0928 00:15:14.536605 29269 net.cpp:113] Setting up pool1_action
I0928 00:15:14.536628 29269 net.cpp:120] Top shape: 70 96 27 27 (4898880)
I0928 00:15:14.536631 29269 net.cpp:126] Memory required for data: 225504720
I0928 00:15:14.536635 29269 layer_factory.hpp:74] Creating layer norm1_action
I0928 00:15:14.536646 29269 net.cpp:84] Creating Layer norm1_action
I0928 00:15:14.536650 29269 net.cpp:384] norm1_action <- pool1_action
I0928 00:15:14.536661 29269 net.cpp:342] norm1_action -> norm1_action
I0928 00:15:14.536670 29269 net.cpp:113] Setting up norm1_action
I0928 00:15:14.536681 29269 net.cpp:120] Top shape: 70 96 27 27 (4898880)
I0928 00:15:14.536684 29269 net.cpp:126] Memory required for data: 245100240
I0928 00:15:14.536689 29269 layer_factory.hpp:74] Creating layer conv2_action
I0928 00:15:14.536700 29269 net.cpp:84] Creating Layer conv2_action
I0928 00:15:14.536705 29269 net.cpp:384] conv2_action <- norm1_action
I0928 00:15:14.536716 29269 net.cpp:342] conv2_action -> conv2_action
I0928 00:15:14.536727 29269 net.cpp:113] Setting up conv2_action
I0928 00:15:14.559432 29269 net.cpp:120] Top shape: 70 256 27 27 (13063680)
I0928 00:15:14.559458 29269 net.cpp:126] Memory required for data: 297354960
I0928 00:15:14.559496 29269 layer_factory.hpp:74] Creating layer relu2_action
I0928 00:15:14.559517 29269 net.cpp:84] Creating Layer relu2_action
I0928 00:15:14.559525 29269 net.cpp:384] relu2_action <- conv2_action
I0928 00:15:14.559551 29269 net.cpp:331] relu2_action -> conv2_action (in-place)
I0928 00:15:14.559562 29269 net.cpp:113] Setting up relu2_action
I0928 00:15:14.559569 29269 net.cpp:120] Top shape: 70 256 27 27 (13063680)
I0928 00:15:14.559572 29269 net.cpp:126] Memory required for data: 349609680
I0928 00:15:14.559576 29269 layer_factory.hpp:74] Creating layer pool2_action
I0928 00:15:14.559593 29269 net.cpp:84] Creating Layer pool2_action
I0928 00:15:14.559597 29269 net.cpp:384] pool2_action <- conv2_action
I0928 00:15:14.559608 29269 net.cpp:342] pool2_action -> pool2_action
I0928 00:15:14.559622 29269 net.cpp:113] Setting up pool2_action
I0928 00:15:14.559636 29269 net.cpp:120] Top shape: 70 256 13 13 (3028480)
I0928 00:15:14.559640 29269 net.cpp:126] Memory required for data: 361723600
I0928 00:15:14.559644 29269 layer_factory.hpp:74] Creating layer norm2_action
I0928 00:15:14.559655 29269 net.cpp:84] Creating Layer norm2_action
I0928 00:15:14.559660 29269 net.cpp:384] norm2_action <- pool2_action
I0928 00:15:14.559670 29269 net.cpp:342] norm2_action -> norm2_action
I0928 00:15:14.559680 29269 net.cpp:113] Setting up norm2_action
I0928 00:15:14.559690 29269 net.cpp:120] Top shape: 70 256 13 13 (3028480)
I0928 00:15:14.559695 29269 net.cpp:126] Memory required for data: 373837520
I0928 00:15:14.559697 29269 layer_factory.hpp:74] Creating layer conv3_action
I0928 00:15:14.559713 29269 net.cpp:84] Creating Layer conv3_action
I0928 00:15:14.559718 29269 net.cpp:384] conv3_action <- norm2_action
I0928 00:15:14.559731 29269 net.cpp:342] conv3_action -> conv3_action
I0928 00:15:14.559741 29269 net.cpp:113] Setting up conv3_action
I0928 00:15:14.619843 29269 net.cpp:120] Top shape: 70 384 13 13 (4542720)
I0928 00:15:14.619869 29269 net.cpp:126] Memory required for data: 392008400
I0928 00:15:14.619910 29269 layer_factory.hpp:74] Creating layer relu3_action
I0928 00:15:14.619931 29269 net.cpp:84] Creating Layer relu3_action
I0928 00:15:14.619940 29269 net.cpp:384] relu3_action <- conv3_action
I0928 00:15:14.619966 29269 net.cpp:331] relu3_action -> conv3_action (in-place)
I0928 00:15:14.619976 29269 net.cpp:113] Setting up relu3_action
I0928 00:15:14.619983 29269 net.cpp:120] Top shape: 70 384 13 13 (4542720)
I0928 00:15:14.619987 29269 net.cpp:126] Memory required for data: 410179280
I0928 00:15:14.619990 29269 layer_factory.hpp:74] Creating layer conv4_action
I0928 00:15:14.620007 29269 net.cpp:84] Creating Layer conv4_action
I0928 00:15:14.620013 29269 net.cpp:384] conv4_action <- conv3_action
I0928 00:15:14.620025 29269 net.cpp:342] conv4_action -> conv4_action
I0928 00:15:14.620046 29269 net.cpp:113] Setting up conv4_action
I0928 00:15:14.665442 29269 net.cpp:120] Top shape: 70 384 13 13 (4542720)
I0928 00:15:14.665468 29269 net.cpp:126] Memory required for data: 428350160
I0928 00:15:14.665499 29269 layer_factory.hpp:74] Creating layer relu4_action
I0928 00:15:14.665520 29269 net.cpp:84] Creating Layer relu4_action
I0928 00:15:14.665529 29269 net.cpp:384] relu4_action <- conv4_action
I0928 00:15:14.665555 29269 net.cpp:331] relu4_action -> conv4_action (in-place)
I0928 00:15:14.665567 29269 net.cpp:113] Setting up relu4_action
I0928 00:15:14.665575 29269 net.cpp:120] Top shape: 70 384 13 13 (4542720)
I0928 00:15:14.665577 29269 net.cpp:126] Memory required for data: 446521040
I0928 00:15:14.665580 29269 layer_factory.hpp:74] Creating layer conv5_action
I0928 00:15:14.665598 29269 net.cpp:84] Creating Layer conv5_action
I0928 00:15:14.665604 29269 net.cpp:384] conv5_action <- conv4_action
I0928 00:15:14.665616 29269 net.cpp:342] conv5_action -> conv5_action
I0928 00:15:14.665628 29269 net.cpp:113] Setting up conv5_action
I0928 00:15:14.696383 29269 net.cpp:120] Top shape: 70 256 13 13 (3028480)
I0928 00:15:14.696408 29269 net.cpp:126] Memory required for data: 458634960
I0928 00:15:14.696449 29269 layer_factory.hpp:74] Creating layer relu5_action
I0928 00:15:14.696471 29269 net.cpp:84] Creating Layer relu5_action
I0928 00:15:14.696480 29269 net.cpp:384] relu5_action <- conv5_action
I0928 00:15:14.696506 29269 net.cpp:331] relu5_action -> conv5_action (in-place)
I0928 00:15:14.696517 29269 net.cpp:113] Setting up relu5_action
I0928 00:15:14.696524 29269 net.cpp:120] Top shape: 70 256 13 13 (3028480)
I0928 00:15:14.696528 29269 net.cpp:126] Memory required for data: 470748880
I0928 00:15:14.696532 29269 layer_factory.hpp:74] Creating layer pool5_action
I0928 00:15:14.696552 29269 net.cpp:84] Creating Layer pool5_action
I0928 00:15:14.696557 29269 net.cpp:384] pool5_action <- conv5_action
I0928 00:15:14.696568 29269 net.cpp:342] pool5_action -> pool5_action
I0928 00:15:14.696578 29269 net.cpp:113] Setting up pool5_action
I0928 00:15:14.696593 29269 net.cpp:120] Top shape: 70 256 6 6 (645120)
I0928 00:15:14.696596 29269 net.cpp:126] Memory required for data: 473329360
I0928 00:15:14.696600 29269 layer_factory.hpp:74] Creating layer fc6_action
I0928 00:15:14.696615 29269 net.cpp:84] Creating Layer fc6_action
I0928 00:15:14.696621 29269 net.cpp:384] fc6_action <- pool5_action
I0928 00:15:14.696632 29269 net.cpp:342] fc6_action -> fc6_action
I0928 00:15:14.696643 29269 net.cpp:113] Setting up fc6_action
I0928 00:15:17.498385 29269 net.cpp:120] Top shape: 70 4096 (286720)
I0928 00:15:17.498406 29269 net.cpp:126] Memory required for data: 474476240
I0928 00:15:17.498426 29269 layer_factory.hpp:74] Creating layer relu6_action
I0928 00:15:17.498447 29269 net.cpp:84] Creating Layer relu6_action
I0928 00:15:17.498456 29269 net.cpp:384] relu6_action <- fc6_action
I0928 00:15:17.498473 29269 net.cpp:331] relu6_action -> fc6_action (in-place)
I0928 00:15:17.498484 29269 net.cpp:113] Setting up relu6_action
I0928 00:15:17.498492 29269 net.cpp:120] Top shape: 70 4096 (286720)
I0928 00:15:17.498494 29269 net.cpp:126] Memory required for data: 475623120
I0928 00:15:17.498498 29269 layer_factory.hpp:74] Creating layer drop6_action
I0928 00:15:17.498508 29269 net.cpp:84] Creating Layer drop6_action
I0928 00:15:17.498512 29269 net.cpp:384] drop6_action <- fc6_action
I0928 00:15:17.498522 29269 net.cpp:331] drop6_action -> fc6_action (in-place)
I0928 00:15:17.498528 29269 net.cpp:113] Setting up drop6_action
I0928 00:15:17.498539 29269 net.cpp:120] Top shape: 70 4096 (286720)
I0928 00:15:17.498543 29269 net.cpp:126] Memory required for data: 476770000
I0928 00:15:17.498546 29269 layer_factory.hpp:74] Creating layer fc7_action
I0928 00:15:17.498560 29269 net.cpp:84] Creating Layer fc7_action
I0928 00:15:17.498565 29269 net.cpp:384] fc7_action <- fc6_action
I0928 00:15:17.498576 29269 net.cpp:342] fc7_action -> fc7_action
I0928 00:15:17.498589 29269 net.cpp:113] Setting up fc7_action
I0928 00:15:18.811735 29269 net.cpp:120] Top shape: 70 4096 (286720)
I0928 00:15:18.811776 29269 net.cpp:126] Memory required for data: 477916880
I0928 00:15:18.811810 29269 layer_factory.hpp:74] Creating layer relu7_action
I0928 00:15:18.811831 29269 net.cpp:84] Creating Layer relu7_action
I0928 00:15:18.811849 29269 net.cpp:384] relu7_action <- fc7_action
I0928 00:15:18.811868 29269 net.cpp:331] relu7_action -> fc7_action (in-place)
I0928 00:15:18.811880 29269 net.cpp:113] Setting up relu7_action
I0928 00:15:18.811887 29269 net.cpp:120] Top shape: 70 4096 (286720)
I0928 00:15:18.811890 29269 net.cpp:126] Memory required for data: 479063760
I0928 00:15:18.811894 29269 layer_factory.hpp:74] Creating layer drop7_action
I0928 00:15:18.811904 29269 net.cpp:84] Creating Layer drop7_action
I0928 00:15:18.811908 29269 net.cpp:384] drop7_action <- fc7_action
I0928 00:15:18.811918 29269 net.cpp:331] drop7_action -> fc7_action (in-place)
I0928 00:15:18.811925 29269 net.cpp:113] Setting up drop7_action
I0928 00:15:18.811936 29269 net.cpp:120] Top shape: 70 4096 (286720)
I0928 00:15:18.811940 29269 net.cpp:126] Memory required for data: 480210640
I0928 00:15:18.811944 29269 layer_factory.hpp:74] Creating layer fc8_CAD_action
I0928 00:15:18.811959 29269 net.cpp:84] Creating Layer fc8_CAD_action
I0928 00:15:18.811964 29269 net.cpp:384] fc8_CAD_action <- fc7_action
I0928 00:15:18.811975 29269 net.cpp:342] fc8_CAD_action -> fc8_CAD_action
I0928 00:15:18.811992 29269 net.cpp:113] Setting up fc8_CAD_action
I0928 00:15:18.813942 29269 net.cpp:120] Top shape: 70 7 (490)
I0928 00:15:18.813948 29269 net.cpp:126] Memory required for data: 480212600
I0928 00:15:18.813958 29269 layer_factory.hpp:74] Creating layer fc8_CAD_action_fc8_CAD_action_0_split
I0928 00:15:18.813967 29269 net.cpp:84] Creating Layer fc8_CAD_action_fc8_CAD_action_0_split
I0928 00:15:18.813972 29269 net.cpp:384] fc8_CAD_action_fc8_CAD_action_0_split <- fc8_CAD_action
I0928 00:15:18.813982 29269 net.cpp:342] fc8_CAD_action_fc8_CAD_action_0_split -> fc8_CAD_action_fc8_CAD_action_0_split_0
I0928 00:15:18.813994 29269 net.cpp:342] fc8_CAD_action_fc8_CAD_action_0_split -> fc8_CAD_action_fc8_CAD_action_0_split_1
I0928 00:15:18.814002 29269 net.cpp:113] Setting up fc8_CAD_action_fc8_CAD_action_0_split
I0928 00:15:18.814013 29269 net.cpp:120] Top shape: 70 7 (490)
I0928 00:15:18.814016 29269 net.cpp:120] Top shape: 70 7 (490)
I0928 00:15:18.814019 29269 net.cpp:126] Memory required for data: 480216520
I0928 00:15:18.814023 29269 layer_factory.hpp:74] Creating layer data_frame
I0928 00:15:18.814039 29269 net.cpp:84] Creating Layer data_frame
I0928 00:15:18.814045 29269 net.cpp:342] data_frame -> data_frame
I0928 00:15:18.814059 29269 net.cpp:342] data_frame -> label_frame
I0928 00:15:18.814067 29269 net.cpp:113] Setting up data_frame
I0928 00:15:18.814122 29269 db.cpp:34] Opened lmdb /media/storage/zhiweid/CollectiveActivityDataset/databases/CAD_frame_val_lmdb_0903
I0928 00:15:18.814229 29269 data_layer.cpp:67] output data size: 5,3,227,227
I0928 00:15:18.814239 29269 data_transformer.cpp:22] Loading mean file from: imagenet_mean.binaryproto
I0928 00:15:18.820324 29269 base_data_layer.cpp:43] Initializing prefetch
I0928 00:15:18.820358 29269 base_data_layer.cpp:45] Prefetch initialized.
I0928 00:15:18.820376 29269 net.cpp:120] Top shape: 5 3 227 227 (772935)
I0928 00:15:18.820380 29269 net.cpp:120] Top shape: 5 (5)
I0928 00:15:18.820384 29269 net.cpp:126] Memory required for data: 483308280
I0928 00:15:18.820389 29269 layer_factory.hpp:74] Creating layer conv1_frame
I0928 00:15:18.820405 29269 net.cpp:84] Creating Layer conv1_frame
I0928 00:15:18.820412 29269 net.cpp:384] conv1_frame <- data_frame
I0928 00:15:18.820428 29269 net.cpp:342] conv1_frame -> conv1_frame
I0928 00:15:18.820441 29269 net.cpp:113] Setting up conv1_frame
I0928 00:15:18.822854 29269 net.cpp:120] Top shape: 5 96 55 55 (1452000)
I0928 00:15:18.822861 29269 net.cpp:126] Memory required for data: 489116280
I0928 00:15:18.822880 29269 layer_factory.hpp:74] Creating layer relu1_frame
I0928 00:15:18.822890 29269 net.cpp:84] Creating Layer relu1_frame
I0928 00:15:18.822901 29269 net.cpp:384] relu1_frame <- conv1_frame
I0928 00:15:18.822919 29269 net.cpp:331] relu1_frame -> conv1_frame (in-place)
I0928 00:15:18.822928 29269 net.cpp:113] Setting up relu1_frame
I0928 00:15:18.822934 29269 net.cpp:120] Top shape: 5 96 55 55 (1452000)
I0928 00:15:18.822937 29269 net.cpp:126] Memory required for data: 494924280
I0928 00:15:18.822942 29269 layer_factory.hpp:74] Creating layer pool1_frame
I0928 00:15:18.822953 29269 net.cpp:84] Creating Layer pool1_frame
I0928 00:15:18.822957 29269 net.cpp:384] pool1_frame <- conv1_frame
I0928 00:15:18.822968 29269 net.cpp:342] pool1_frame -> pool1_frame
I0928 00:15:18.822978 29269 net.cpp:113] Setting up pool1_frame
I0928 00:15:18.822991 29269 net.cpp:120] Top shape: 5 96 27 27 (349920)
I0928 00:15:18.822995 29269 net.cpp:126] Memory required for data: 496323960
I0928 00:15:18.822999 29269 layer_factory.hpp:74] Creating layer norm1_frame
I0928 00:15:18.823010 29269 net.cpp:84] Creating Layer norm1_frame
I0928 00:15:18.823015 29269 net.cpp:384] norm1_frame <- pool1_frame
I0928 00:15:18.823025 29269 net.cpp:342] norm1_frame -> norm1_frame
I0928 00:15:18.823035 29269 net.cpp:113] Setting up norm1_frame
I0928 00:15:18.823046 29269 net.cpp:120] Top shape: 5 96 27 27 (349920)
I0928 00:15:18.823050 29269 net.cpp:126] Memory required for data: 497723640
I0928 00:15:18.823053 29269 layer_factory.hpp:74] Creating layer conv2_frame
I0928 00:15:18.823065 29269 net.cpp:84] Creating Layer conv2_frame
I0928 00:15:18.823071 29269 net.cpp:384] conv2_frame <- norm1_frame
I0928 00:15:18.823082 29269 net.cpp:342] conv2_frame -> conv2_frame
I0928 00:15:18.823093 29269 net.cpp:113] Setting up conv2_frame
I0928 00:15:18.844071 29269 net.cpp:120] Top shape: 5 256 27 27 (933120)
I0928 00:15:18.844081 29269 net.cpp:126] Memory required for data: 501456120
I0928 00:15:18.844101 29269 layer_factory.hpp:74] Creating layer relu2_frame
I0928 00:15:18.844112 29269 net.cpp:84] Creating Layer relu2_frame
I0928 00:15:18.844118 29269 net.cpp:384] relu2_frame <- conv2_frame
I0928 00:15:18.844128 29269 net.cpp:331] relu2_frame -> conv2_frame (in-place)
I0928 00:15:18.844146 29269 net.cpp:113] Setting up relu2_frame
I0928 00:15:18.844152 29269 net.cpp:120] Top shape: 5 256 27 27 (933120)
I0928 00:15:18.844156 29269 net.cpp:126] Memory required for data: 505188600
I0928 00:15:18.844158 29269 layer_factory.hpp:74] Creating layer pool2_frame
I0928 00:15:18.844174 29269 net.cpp:84] Creating Layer pool2_frame
I0928 00:15:18.844179 29269 net.cpp:384] pool2_frame <- conv2_frame
I0928 00:15:18.844189 29269 net.cpp:342] pool2_frame -> pool2_frame
I0928 00:15:18.844199 29269 net.cpp:113] Setting up pool2_frame
I0928 00:15:18.844213 29269 net.cpp:120] Top shape: 5 256 13 13 (216320)
I0928 00:15:18.844215 29269 net.cpp:126] Memory required for data: 506053880
I0928 00:15:18.844219 29269 layer_factory.hpp:74] Creating layer norm2_frame
I0928 00:15:18.844228 29269 net.cpp:84] Creating Layer norm2_frame
I0928 00:15:18.844233 29269 net.cpp:384] norm2_frame <- pool2_frame
I0928 00:15:18.844244 29269 net.cpp:342] norm2_frame -> norm2_frame
I0928 00:15:18.844252 29269 net.cpp:113] Setting up norm2_frame
I0928 00:15:18.844262 29269 net.cpp:120] Top shape: 5 256 13 13 (216320)
I0928 00:15:18.844266 29269 net.cpp:126] Memory required for data: 506919160
I0928 00:15:18.844269 29269 layer_factory.hpp:74] Creating layer conv3_frame
I0928 00:15:18.844281 29269 net.cpp:84] Creating Layer conv3_frame
I0928 00:15:18.844286 29269 net.cpp:384] conv3_frame <- norm2_frame
I0928 00:15:18.844297 29269 net.cpp:342] conv3_frame -> conv3_frame
I0928 00:15:18.844307 29269 net.cpp:113] Setting up conv3_frame
I0928 00:15:18.905510 29269 net.cpp:120] Top shape: 5 384 13 13 (324480)
I0928 00:15:18.905522 29269 net.cpp:126] Memory required for data: 508217080
I0928 00:15:18.905534 29269 layer_factory.hpp:74] Creating layer relu3_frame
I0928 00:15:18.905547 29269 net.cpp:84] Creating Layer relu3_frame
I0928 00:15:18.905553 29269 net.cpp:384] relu3_frame <- conv3_frame
I0928 00:15:18.905565 29269 net.cpp:331] relu3_frame -> conv3_frame (in-place)
I0928 00:15:18.905580 29269 net.cpp:113] Setting up relu3_frame
I0928 00:15:18.905594 29269 net.cpp:120] Top shape: 5 384 13 13 (324480)
I0928 00:15:18.905597 29269 net.cpp:126] Memory required for data: 509515000
I0928 00:15:18.905601 29269 layer_factory.hpp:74] Creating layer conv4_frame
I0928 00:15:18.905616 29269 net.cpp:84] Creating Layer conv4_frame
I0928 00:15:18.905621 29269 net.cpp:384] conv4_frame <- conv3_frame
I0928 00:15:18.905633 29269 net.cpp:342] conv4_frame -> conv4_frame
I0928 00:15:18.905643 29269 net.cpp:113] Setting up conv4_frame
I0928 00:15:18.951349 29269 net.cpp:120] Top shape: 5 384 13 13 (324480)
I0928 00:15:18.951359 29269 net.cpp:126] Memory required for data: 510812920
I0928 00:15:18.951380 29269 layer_factory.hpp:74] Creating layer relu4_frame
I0928 00:15:18.951390 29269 net.cpp:84] Creating Layer relu4_frame
I0928 00:15:18.951395 29269 net.cpp:384] relu4_frame <- conv4_frame
I0928 00:15:18.951406 29269 net.cpp:331] relu4_frame -> conv4_frame (in-place)
I0928 00:15:18.951424 29269 net.cpp:113] Setting up relu4_frame
I0928 00:15:18.951431 29269 net.cpp:120] Top shape: 5 384 13 13 (324480)
I0928 00:15:18.951433 29269 net.cpp:126] Memory required for data: 512110840
I0928 00:15:18.951436 29269 layer_factory.hpp:74] Creating layer conv5_frame
I0928 00:15:18.951448 29269 net.cpp:84] Creating Layer conv5_frame
I0928 00:15:18.951453 29269 net.cpp:384] conv5_frame <- conv4_frame
I0928 00:15:18.951464 29269 net.cpp:342] conv5_frame -> conv5_frame
I0928 00:15:18.951475 29269 net.cpp:113] Setting up conv5_frame
I0928 00:15:18.983924 29269 net.cpp:120] Top shape: 5 256 13 13 (216320)
I0928 00:15:18.983934 29269 net.cpp:126] Memory required for data: 512976120
I0928 00:15:18.983945 29269 layer_factory.hpp:74] Creating layer relu5_frame
I0928 00:15:18.983957 29269 net.cpp:84] Creating Layer relu5_frame
I0928 00:15:18.983961 29269 net.cpp:384] relu5_frame <- conv5_frame
I0928 00:15:18.983973 29269 net.cpp:331] relu5_frame -> conv5_frame (in-place)
I0928 00:15:18.983980 29269 net.cpp:113] Setting up relu5_frame
I0928 00:15:18.983988 29269 net.cpp:120] Top shape: 5 256 13 13 (216320)
I0928 00:15:18.983990 29269 net.cpp:126] Memory required for data: 513841400
I0928 00:15:18.983994 29269 layer_factory.hpp:74] Creating layer pool5_frame
I0928 00:15:18.984005 29269 net.cpp:84] Creating Layer pool5_frame
I0928 00:15:18.984010 29269 net.cpp:384] pool5_frame <- conv5_frame
I0928 00:15:18.984021 29269 net.cpp:342] pool5_frame -> pool5_frame
I0928 00:15:18.984031 29269 net.cpp:113] Setting up pool5_frame
I0928 00:15:18.984046 29269 net.cpp:120] Top shape: 5 256 6 6 (46080)
I0928 00:15:18.984050 29269 net.cpp:126] Memory required for data: 514025720
I0928 00:15:18.984055 29269 layer_factory.hpp:74] Creating layer fc6_frame
I0928 00:15:18.984067 29269 net.cpp:84] Creating Layer fc6_frame
I0928 00:15:18.984073 29269 net.cpp:384] fc6_frame <- pool5_frame
I0928 00:15:18.984086 29269 net.cpp:342] fc6_frame -> fc6_frame
I0928 00:15:18.984097 29269 net.cpp:113] Setting up fc6_frame
I0928 00:15:21.763296 29269 net.cpp:120] Top shape: 5 4096 (20480)
I0928 00:15:21.763321 29269 net.cpp:126] Memory required for data: 514107640
I0928 00:15:21.763344 29269 layer_factory.hpp:74] Creating layer relu6_frame
I0928 00:15:21.763365 29269 net.cpp:84] Creating Layer relu6_frame
I0928 00:15:21.763375 29269 net.cpp:384] relu6_frame <- fc6_frame
I0928 00:15:21.763392 29269 net.cpp:331] relu6_frame -> fc6_frame (in-place)
I0928 00:15:21.763404 29269 net.cpp:113] Setting up relu6_frame
I0928 00:15:21.763412 29269 net.cpp:120] Top shape: 5 4096 (20480)
I0928 00:15:21.763416 29269 net.cpp:126] Memory required for data: 514189560
I0928 00:15:21.763419 29269 layer_factory.hpp:74] Creating layer drop6_frame
I0928 00:15:21.763429 29269 net.cpp:84] Creating Layer drop6_frame
I0928 00:15:21.763434 29269 net.cpp:384] drop6_frame <- fc6_frame
I0928 00:15:21.763443 29269 net.cpp:331] drop6_frame -> fc6_frame (in-place)
I0928 00:15:21.763450 29269 net.cpp:113] Setting up drop6_frame
I0928 00:15:21.763461 29269 net.cpp:120] Top shape: 5 4096 (20480)
I0928 00:15:21.763475 29269 net.cpp:126] Memory required for data: 514271480
I0928 00:15:21.763489 29269 layer_factory.hpp:74] Creating layer fc7_frame
I0928 00:15:21.763504 29269 net.cpp:84] Creating Layer fc7_frame
I0928 00:15:21.763509 29269 net.cpp:384] fc7_frame <- fc6_frame
I0928 00:15:21.763521 29269 net.cpp:342] fc7_frame -> fc7_frame
I0928 00:15:21.763541 29269 net.cpp:113] Setting up fc7_frame
I0928 00:15:22.920719 29269 net.cpp:120] Top shape: 5 4096 (20480)
I0928 00:15:22.920744 29269 net.cpp:126] Memory required for data: 514353400
I0928 00:15:22.920775 29269 layer_factory.hpp:74] Creating layer relu7_frame
I0928 00:15:22.920799 29269 net.cpp:84] Creating Layer relu7_frame
I0928 00:15:22.920807 29269 net.cpp:384] relu7_frame <- fc7_frame
I0928 00:15:22.920835 29269 net.cpp:331] relu7_frame -> fc7_frame (in-place)
I0928 00:15:22.920847 29269 net.cpp:113] Setting up relu7_frame
I0928 00:15:22.920855 29269 net.cpp:120] Top shape: 5 4096 (20480)
I0928 00:15:22.920857 29269 net.cpp:126] Memory required for data: 514435320
I0928 00:15:22.920861 29269 layer_factory.hpp:74] Creating layer drop7_frame
I0928 00:15:22.920871 29269 net.cpp:84] Creating Layer drop7_frame
I0928 00:15:22.920876 29269 net.cpp:384] drop7_frame <- fc7_frame
I0928 00:15:22.920886 29269 net.cpp:331] drop7_frame -> fc7_frame (in-place)
I0928 00:15:22.920893 29269 net.cpp:113] Setting up drop7_frame
I0928 00:15:22.920904 29269 net.cpp:120] Top shape: 5 4096 (20480)
I0928 00:15:22.920907 29269 net.cpp:126] Memory required for data: 514517240
I0928 00:15:22.920912 29269 layer_factory.hpp:74] Creating layer fc8_CAD_frame
I0928 00:15:22.920925 29269 net.cpp:84] Creating Layer fc8_CAD_frame
I0928 00:15:22.920930 29269 net.cpp:384] fc8_CAD_frame <- fc7_frame
I0928 00:15:22.920943 29269 net.cpp:342] fc8_CAD_frame -> fc8_CAD_frame
I0928 00:15:22.920954 29269 net.cpp:113] Setting up fc8_CAD_frame
I0928 00:15:22.922440 29269 net.cpp:120] Top shape: 5 5 (25)
I0928 00:15:22.922446 29269 net.cpp:126] Memory required for data: 514517340
I0928 00:15:22.922456 29269 layer_factory.hpp:74] Creating layer prob_frame
I0928 00:15:22.922466 29269 net.cpp:84] Creating Layer prob_frame
I0928 00:15:22.922471 29269 net.cpp:384] prob_frame <- fc8_CAD_frame
I0928 00:15:22.922480 29269 net.cpp:342] prob_frame -> fc8_CAD_frame_prob
I0928 00:15:22.922490 29269 net.cpp:113] Setting up prob_frame
I0928 00:15:22.922502 29269 net.cpp:120] Top shape: 5 5 (25)
I0928 00:15:22.922505 29269 net.cpp:126] Memory required for data: 514517440
I0928 00:15:22.922509 29269 layer_factory.hpp:74] Creating layer prob_action
I0928 00:15:22.922518 29269 net.cpp:84] Creating Layer prob_action
I0928 00:15:22.922521 29269 net.cpp:384] prob_action <- fc8_CAD_action_fc8_CAD_action_0_split_0
I0928 00:15:22.922531 29269 net.cpp:342] prob_action -> fc8_CAD_prob
I0928 00:15:22.922539 29269 net.cpp:113] Setting up prob_action
I0928 00:15:22.922550 29269 net.cpp:120] Top shape: 70 7 (490)
I0928 00:15:22.922554 29269 net.cpp:126] Memory required for data: 514519400
I0928 00:15:22.922559 29269 layer_factory.hpp:74] Creating layer Data_arrange_layer_filter
I0928 00:15:22.922629 29269 net.cpp:84] Creating Layer Data_arrange_layer_filter
I0928 00:15:22.922637 29269 net.cpp:384] Data_arrange_layer_filter <- fc8_CAD_action_fc8_CAD_action_0_split_1
I0928 00:15:22.922647 29269 net.cpp:384] Data_arrange_layer_filter <- label_action_data_action_1_split_0
I0928 00:15:22.922658 29269 net.cpp:342] Data_arrange_layer_filter -> fc9_filtered
I0928 00:15:22.922667 29269 net.cpp:113] Setting up Data_arrange_layer_filter
I0928 00:15:22.922755 29269 net.cpp:120] Top shape: 5 98 (490)
I0928 00:15:22.922762 29269 net.cpp:126] Memory required for data: 514521360
I0928 00:15:22.922767 29269 layer_factory.hpp:74] Creating layer concatenation_s_a_p
I0928 00:15:22.922778 29269 net.cpp:84] Creating Layer concatenation_s_a_p
I0928 00:15:22.922783 29269 net.cpp:384] concatenation_s_a_p <- fc8_CAD_frame_prob
I0928 00:15:22.922792 29269 net.cpp:384] concatenation_s_a_p <- fc9_filtered
I0928 00:15:22.922801 29269 net.cpp:342] concatenation_s_a_p -> concat_all
I0928 00:15:22.922819 29269 net.cpp:113] Setting up concatenation_s_a_p
I0928 00:15:22.922838 29269 net.cpp:120] Top shape: 5 103 (515)
I0928 00:15:22.922842 29269 net.cpp:126] Memory required for data: 514523420
I0928 00:15:22.922847 29269 layer_factory.hpp:74] Creating layer simplified_message_in
I0928 00:15:22.922878 29269 net.cpp:84] Creating Layer simplified_message_in
I0928 00:15:22.922886 29269 net.cpp:384] simplified_message_in <- concat_all
I0928 00:15:22.922895 29269 net.cpp:384] simplified_message_in <- label_action_data_action_1_split_1
I0928 00:15:22.922905 29269 net.cpp:342] simplified_message_in -> a2a
I0928 00:15:22.922917 29269 net.cpp:342] simplified_message_in -> s2a
I0928 00:15:22.922927 29269 net.cpp:342] simplified_message_in -> a2s
I0928 00:15:22.922935 29269 net.cpp:113] Setting up simplified_message_in
I0928 00:15:22.923404 29269 net.cpp:120] Top shape: 0 7 (0)
I0928 00:15:22.923415 29269 net.cpp:120] Top shape: 0 7 (0)
I0928 00:15:22.923418 29269 net.cpp:120] Top shape: 0 5 (0)
I0928 00:15:22.923421 29269 net.cpp:126] Memory required for data: 514523420
I0928 00:15:22.923429 29269 net.cpp:169] simplified_message_in does not need backward computation.
I0928 00:15:22.923431 29269 net.cpp:169] concatenation_s_a_p does not need backward computation.
I0928 00:15:22.923434 29269 net.cpp:169] Data_arrange_layer_filter does not need backward computation.
I0928 00:15:22.923436 29269 net.cpp:169] prob_action does not need backward computation.
I0928 00:15:22.923439 29269 net.cpp:169] prob_frame does not need backward computation.
I0928 00:15:22.923442 29269 net.cpp:169] fc8_CAD_frame does not need backward computation.
I0928 00:15:22.923444 29269 net.cpp:169] drop7_frame does not need backward computation.
I0928 00:15:22.923447 29269 net.cpp:169] relu7_frame does not need backward computation.
I0928 00:15:22.923450 29269 net.cpp:169] fc7_frame does not need backward computation.
I0928 00:15:22.923454 29269 net.cpp:169] drop6_frame does not need backward computation.
I0928 00:15:22.923455 29269 net.cpp:169] relu6_frame does not need backward computation.
I0928 00:15:22.923459 29269 net.cpp:169] fc6_frame does not need backward computation.
I0928 00:15:22.923461 29269 net.cpp:169] pool5_frame does not need backward computation.
I0928 00:15:22.923465 29269 net.cpp:169] relu5_frame does not need backward computation.
I0928 00:15:22.923467 29269 net.cpp:169] conv5_frame does not need backward computation.
I0928 00:15:22.923470 29269 net.cpp:169] relu4_frame does not need backward computation.
I0928 00:15:22.923472 29269 net.cpp:169] conv4_frame does not need backward computation.
I0928 00:15:22.923475 29269 net.cpp:169] relu3_frame does not need backward computation.
I0928 00:15:22.923478 29269 net.cpp:169] conv3_frame does not need backward computation.
I0928 00:15:22.923481 29269 net.cpp:169] norm2_frame does not need backward computation.
I0928 00:15:22.923483 29269 net.cpp:169] pool2_frame does not need backward computation.
I0928 00:15:22.923486 29269 net.cpp:169] relu2_frame does not need backward computation.
I0928 00:15:22.923490 29269 net.cpp:169] conv2_frame does not need backward computation.
I0928 00:15:22.923492 29269 net.cpp:169] norm1_frame does not need backward computation.
I0928 00:15:22.923496 29269 net.cpp:169] pool1_frame does not need backward computation.
I0928 00:15:22.923497 29269 net.cpp:169] relu1_frame does not need backward computation.
I0928 00:15:22.923501 29269 net.cpp:169] conv1_frame does not need backward computation.
I0928 00:15:22.923503 29269 net.cpp:169] data_frame does not need backward computation.
I0928 00:15:22.923506 29269 net.cpp:169] fc8_CAD_action_fc8_CAD_action_0_split does not need backward computation.
I0928 00:15:22.923509 29269 net.cpp:169] fc8_CAD_action does not need backward computation.
I0928 00:15:22.923512 29269 net.cpp:169] drop7_action does not need backward computation.
I0928 00:15:22.923516 29269 net.cpp:169] relu7_action does not need backward computation.
I0928 00:15:22.923518 29269 net.cpp:169] fc7_action does not need backward computation.
I0928 00:15:22.923526 29269 net.cpp:169] drop6_action does not need backward computation.
I0928 00:15:22.923534 29269 net.cpp:169] relu6_action does not need backward computation.
I0928 00:15:22.923537 29269 net.cpp:169] fc6_action does not need backward computation.
I0928 00:15:22.923540 29269 net.cpp:169] pool5_action does not need backward computation.
I0928 00:15:22.923543 29269 net.cpp:169] relu5_action does not need backward computation.
I0928 00:15:22.923547 29269 net.cpp:169] conv5_action does not need backward computation.
I0928 00:15:22.923549 29269 net.cpp:169] relu4_action does not need backward computation.
I0928 00:15:22.923552 29269 net.cpp:169] conv4_action does not need backward computation.
I0928 00:15:22.923554 29269 net.cpp:169] relu3_action does not need backward computation.
I0928 00:15:22.923557 29269 net.cpp:169] conv3_action does not need backward computation.
I0928 00:15:22.923560 29269 net.cpp:169] norm2_action does not need backward computation.
I0928 00:15:22.923563 29269 net.cpp:169] pool2_action does not need backward computation.
I0928 00:15:22.923565 29269 net.cpp:169] relu2_action does not need backward computation.
I0928 00:15:22.923568 29269 net.cpp:169] conv2_action does not need backward computation.
I0928 00:15:22.923571 29269 net.cpp:169] norm1_action does not need backward computation.
I0928 00:15:22.923574 29269 net.cpp:169] pool1_action does not need backward computation.
I0928 00:15:22.923578 29269 net.cpp:169] relu1_action does not need backward computation.
I0928 00:15:22.923580 29269 net.cpp:169] conv1_action does not need backward computation.
I0928 00:15:22.923583 29269 net.cpp:169] label_action_data_action_1_split does not need backward computation.
I0928 00:15:22.923585 29269 net.cpp:169] data_action does not need backward computation.
I0928 00:15:22.923610 29269 net.cpp:208] This network produces output a2a
I0928 00:15:22.923617 29269 net.cpp:208] This network produces output a2s
I0928 00:15:22.923621 29269 net.cpp:208] This network produces output fc8_CAD_prob
I0928 00:15:22.923626 29269 net.cpp:208] This network produces output label_frame
I0928 00:15:22.923630 29269 net.cpp:208] This network produces output s2a
I0928 00:15:22.923674 29269 net.cpp:449] Collecting Learning Rate and Weight Decay.
I0928 00:15:22.923688 29269 net.cpp:221] Network initialization done.
I0928 00:15:22.923691 29269 net.cpp:222] Memory required for data: 514523420
I0928 00:15:22.923867 29269 solver.cpp:42] Solver scaffolding done.
I0928 00:15:22.923966 29269 caffe.cpp:86] Finetuning from net_surgery_forzhiwei.caffemodel
libprotobuf WARNING google/protobuf/io/coded_stream.cc:487] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
I0928 00:15:28.205261 29269 net.cpp:704] Copying source layer data_action
I0928 00:15:28.205294 29269 net.cpp:704] Copying source layer conv1_action
I0928 00:15:28.205601 29269 net.cpp:704] Copying source layer relu1_action
I0928 00:15:28.205606 29269 net.cpp:704] Copying source layer pool1_action
I0928 00:15:28.205610 29269 net.cpp:704] Copying source layer norm1_action
I0928 00:15:28.205612 29269 net.cpp:704] Copying source layer conv2_action
I0928 00:15:28.208067 29269 net.cpp:704] Copying source layer relu2_action
I0928 00:15:28.208073 29269 net.cpp:704] Copying source layer pool2_action
I0928 00:15:28.208076 29269 net.cpp:704] Copying source layer norm2_action
I0928 00:15:28.208080 29269 net.cpp:704] Copying source layer conv3_action
I0928 00:15:28.215178 29269 net.cpp:704] Copying source layer relu3_action
I0928 00:15:28.215186 29269 net.cpp:704] Copying source layer conv4_action
I0928 00:15:28.221007 29269 net.cpp:704] Copying source layer relu4_action
I0928 00:15:28.221019 29269 net.cpp:704] Copying source layer conv5_action
I0928 00:15:28.224663 29269 net.cpp:704] Copying source layer relu5_action
I0928 00:15:28.224676 29269 net.cpp:704] Copying source layer pool5_action
I0928 00:15:28.224679 29269 net.cpp:704] Copying source layer fc6_action
I0928 00:15:28.528873 29269 net.cpp:704] Copying source layer relu6_action
I0928 00:15:28.528903 29269 net.cpp:704] Copying source layer drop6_action
I0928 00:15:28.528909 29269 net.cpp:704] Copying source layer fc7_action
I0928 00:15:28.663326 29269 net.cpp:704] Copying source layer relu7_action
I0928 00:15:28.663363 29269 net.cpp:704] Copying source layer drop7_action
I0928 00:15:28.663368 29269 net.cpp:704] Copying source layer fc8_CAD_action
I0928 00:15:28.663604 29269 net.cpp:701] Ignoring source layer data_pose
I0928 00:15:28.663609 29269 net.cpp:701] Ignoring source layer conv1_pose
I0928 00:15:28.663612 29269 net.cpp:701] Ignoring source layer relu1_pose
I0928 00:15:28.663615 29269 net.cpp:701] Ignoring source layer pool1_pose
I0928 00:15:28.663619 29269 net.cpp:701] Ignoring source layer norm1_pose
I0928 00:15:28.663621 29269 net.cpp:701] Ignoring source layer conv2_pose
I0928 00:15:28.663625 29269 net.cpp:701] Ignoring source layer relu2_pose
I0928 00:15:28.663627 29269 net.cpp:701] Ignoring source layer pool2_pose
I0928 00:15:28.663631 29269 net.cpp:701] Ignoring source layer norm2_pose
I0928 00:15:28.663635 29269 net.cpp:701] Ignoring source layer conv3_pose
I0928 00:15:28.663637 29269 net.cpp:701] Ignoring source layer relu3_pose
I0928 00:15:28.663640 29269 net.cpp:701] Ignoring source layer conv4_pose
I0928 00:15:28.663645 29269 net.cpp:701] Ignoring source layer relu4_pose
I0928 00:15:28.663647 29269 net.cpp:701] Ignoring source layer conv5_pose
I0928 00:15:28.663650 29269 net.cpp:701] Ignoring source layer relu5_pose
I0928 00:15:28.663653 29269 net.cpp:701] Ignoring source layer pool5_pose
I0928 00:15:28.663656 29269 net.cpp:701] Ignoring source layer fc6_pose
I0928 00:15:28.663660 29269 net.cpp:701] Ignoring source layer relu6_pose
I0928 00:15:28.663662 29269 net.cpp:701] Ignoring source layer drop6_pose
I0928 00:15:28.663666 29269 net.cpp:701] Ignoring source layer fc7_pose
I0928 00:15:28.663669 29269 net.cpp:701] Ignoring source layer relu7_pose
I0928 00:15:28.663672 29269 net.cpp:701] Ignoring source layer drop7_pose
I0928 00:15:28.663676 29269 net.cpp:701] Ignoring source layer fc8_pose
I0928 00:15:28.663678 29269 net.cpp:704] Copying source layer data_frame
I0928 00:15:28.663681 29269 net.cpp:704] Copying source layer conv1_frame
I0928 00:15:28.663969 29269 net.cpp:704] Copying source layer relu1_frame
I0928 00:15:28.663972 29269 net.cpp:704] Copying source layer pool1_frame
I0928 00:15:28.663975 29269 net.cpp:704] Copying source layer norm1_frame
I0928 00:15:28.663979 29269 net.cpp:704] Copying source layer conv2_frame
I0928 00:15:28.666425 29269 net.cpp:704] Copying source layer relu2_frame
I0928 00:15:28.666430 29269 net.cpp:704] Copying source layer pool2_frame
I0928 00:15:28.666434 29269 net.cpp:704] Copying source layer norm2_frame
I0928 00:15:28.666437 29269 net.cpp:704] Copying source layer conv3_frame
I0928 00:15:28.673535 29269 net.cpp:704] Copying source layer relu3_frame
I0928 00:15:28.673545 29269 net.cpp:704] Copying source layer conv4_frame
I0928 00:15:28.678961 29269 net.cpp:704] Copying source layer relu4_frame
I0928 00:15:28.678967 29269 net.cpp:704] Copying source layer conv5_frame
I0928 00:15:28.682479 29269 net.cpp:704] Copying source layer relu5_frame
I0928 00:15:28.682485 29269 net.cpp:704] Copying source layer pool5_frame
I0928 00:15:28.682488 29269 net.cpp:704] Copying source layer fc6_frame
I0928 00:15:28.988529 29269 net.cpp:704] Copying source layer relu6_frame
I0928 00:15:28.988556 29269 net.cpp:704] Copying source layer drop6_frame
I0928 00:15:28.988560 29269 net.cpp:704] Copying source layer fc7_frame
I0928 00:15:29.123152 29269 net.cpp:704] Copying source layer relu7_frame
I0928 00:15:29.123181 29269 net.cpp:704] Copying source layer drop7_frame
I0928 00:15:29.123186 29269 net.cpp:704] Copying source layer fc8_CAD_frame
libprotobuf WARNING google/protobuf/io/coded_stream.cc:487] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
I0928 00:15:34.115242 29269 net.cpp:704] Copying source layer data_action
I0928 00:15:34.115273 29269 net.cpp:704] Copying source layer conv1_action
I0928 00:15:34.115573 29269 net.cpp:704] Copying source layer relu1_action
I0928 00:15:34.115578 29269 net.cpp:704] Copying source layer pool1_action
I0928 00:15:34.115581 29269 net.cpp:704] Copying source layer norm1_action
I0928 00:15:34.115584 29269 net.cpp:704] Copying source layer conv2_action
I0928 00:15:34.118028 29269 net.cpp:704] Copying source layer relu2_action
I0928 00:15:34.118047 29269 net.cpp:704] Copying source layer pool2_action
I0928 00:15:34.118051 29269 net.cpp:704] Copying source layer norm2_action
I0928 00:15:34.118053 29269 net.cpp:704] Copying source layer conv3_action
I0928 00:15:34.125072 29269 net.cpp:704] Copying source layer relu3_action
I0928 00:15:34.125080 29269 net.cpp:704] Copying source layer conv4_action
I0928 00:15:34.130378 29269 net.cpp:704] Copying source layer relu4_action
I0928 00:15:34.130385 29269 net.cpp:704] Copying source layer conv5_action
I0928 00:15:34.133882 29269 net.cpp:704] Copying source layer relu5_action
I0928 00:15:34.133888 29269 net.cpp:704] Copying source layer pool5_action
I0928 00:15:34.133890 29269 net.cpp:704] Copying source layer fc6_action
I0928 00:15:34.437808 29269 net.cpp:704] Copying source layer relu6_action
I0928 00:15:34.437837 29269 net.cpp:704] Copying source layer drop6_action
I0928 00:15:34.437842 29269 net.cpp:704] Copying source layer fc7_action
I0928 00:15:34.571632 29269 net.cpp:704] Copying source layer relu7_action
I0928 00:15:34.571661 29269 net.cpp:704] Copying source layer drop7_action
I0928 00:15:34.571666 29269 net.cpp:704] Copying source layer fc8_CAD_action
I0928 00:15:34.571908 29269 net.cpp:701] Ignoring source layer data_pose
I0928 00:15:34.571913 29269 net.cpp:701] Ignoring source layer conv1_pose
I0928 00:15:34.571918 29269 net.cpp:701] Ignoring source layer relu1_pose
I0928 00:15:34.571921 29269 net.cpp:701] Ignoring source layer pool1_pose
I0928 00:15:34.571924 29269 net.cpp:701] Ignoring source layer norm1_pose
I0928 00:15:34.571928 29269 net.cpp:701] Ignoring source layer conv2_pose
I0928 00:15:34.571930 29269 net.cpp:701] Ignoring source layer relu2_pose
I0928 00:15:34.571933 29269 net.cpp:701] Ignoring source layer pool2_pose
I0928 00:15:34.571938 29269 net.cpp:701] Ignoring source layer norm2_pose
I0928 00:15:34.571940 29269 net.cpp:701] Ignoring source layer conv3_pose
I0928 00:15:34.571943 29269 net.cpp:701] Ignoring source layer relu3_pose
I0928 00:15:34.571946 29269 net.cpp:701] Ignoring source layer conv4_pose
I0928 00:15:34.571949 29269 net.cpp:701] Ignoring source layer relu4_pose
I0928 00:15:34.571954 29269 net.cpp:701] Ignoring source layer conv5_pose
I0928 00:15:34.571956 29269 net.cpp:701] Ignoring source layer relu5_pose
I0928 00:15:34.571959 29269 net.cpp:701] Ignoring source layer pool5_pose
I0928 00:15:34.571962 29269 net.cpp:701] Ignoring source layer fc6_pose
I0928 00:15:34.571965 29269 net.cpp:701] Ignoring source layer relu6_pose
I0928 00:15:34.571969 29269 net.cpp:701] Ignoring source layer drop6_pose
I0928 00:15:34.571972 29269 net.cpp:701] Ignoring source layer fc7_pose
I0928 00:15:34.571975 29269 net.cpp:701] Ignoring source layer relu7_pose
I0928 00:15:34.571979 29269 net.cpp:701] Ignoring source layer drop7_pose
I0928 00:15:34.571981 29269 net.cpp:701] Ignoring source layer fc8_pose
I0928 00:15:34.571985 29269 net.cpp:704] Copying source layer data_frame
I0928 00:15:34.571987 29269 net.cpp:704] Copying source layer conv1_frame
I0928 00:15:34.572271 29269 net.cpp:704] Copying source layer relu1_frame
I0928 00:15:34.572275 29269 net.cpp:704] Copying source layer pool1_frame
I0928 00:15:34.572278 29269 net.cpp:704] Copying source layer norm1_frame
I0928 00:15:34.572281 29269 net.cpp:704] Copying source layer conv2_frame
I0928 00:15:34.574784 29269 net.cpp:704] Copying source layer relu2_frame
I0928 00:15:34.574790 29269 net.cpp:704] Copying source layer pool2_frame
I0928 00:15:34.574792 29269 net.cpp:704] Copying source layer norm2_frame
I0928 00:15:34.574795 29269 net.cpp:704] Copying source layer conv3_frame
I0928 00:15:34.581897 29269 net.cpp:704] Copying source layer relu3_frame
I0928 00:15:34.581907 29269 net.cpp:704] Copying source layer conv4_frame
I0928 00:15:34.587163 29269 net.cpp:704] Copying source layer relu4_frame
I0928 00:15:34.587169 29269 net.cpp:704] Copying source layer conv5_frame
I0928 00:15:34.590687 29269 net.cpp:704] Copying source layer relu5_frame
I0928 00:15:34.590692 29269 net.cpp:704] Copying source layer pool5_frame
I0928 00:15:34.590708 29269 net.cpp:704] Copying source layer fc6_frame
I0928 00:15:34.892882 29269 net.cpp:704] Copying source layer relu6_frame
I0928 00:15:34.892926 29269 net.cpp:704] Copying source layer drop6_frame
I0928 00:15:34.892933 29269 net.cpp:704] Copying source layer fc7_frame
I0928 00:15:35.028990 29269 net.cpp:704] Copying source layer relu7_frame
I0928 00:15:35.029021 29269 net.cpp:704] Copying source layer drop7_frame
I0928 00:15:35.029026 29269 net.cpp:704] Copying source layer fc8_CAD_frame
I0928 00:15:35.058614 29269 solver.cpp:247] Solving CaffeNet
I0928 00:15:35.058643 29269 solver.cpp:248] Learning Rate Policy: step
I0928 00:15:35.060360 29269 solver.cpp:291] Iteration 0, Testing net (#0)
I0928 00:15:35.060376 29269 net.cpp:639] Copying source layer data_action
I0928 00:15:35.060381 29269 net.cpp:639] Copying source layer label_action_data_action_1_split
I0928 00:15:35.060384 29269 net.cpp:639] Copying source layer conv1_action
I0928 00:15:35.060400 29269 net.cpp:639] Copying source layer relu1_action
I0928 00:15:35.060403 29269 net.cpp:639] Copying source layer pool1_action
I0928 00:15:35.060406 29269 net.cpp:639] Copying source layer norm1_action
I0928 00:15:35.060410 29269 net.cpp:639] Copying source layer conv2_action
I0928 00:15:35.060415 29269 net.cpp:639] Copying source layer relu2_action
I0928 00:15:35.060417 29269 net.cpp:639] Copying source layer pool2_action
I0928 00:15:35.060420 29269 net.cpp:639] Copying source layer norm2_action
I0928 00:15:35.060423 29269 net.cpp:639] Copying source layer conv3_action
I0928 00:15:35.060428 29269 net.cpp:639] Copying source layer relu3_action
I0928 00:15:35.060431 29269 net.cpp:639] Copying source layer conv4_action
I0928 00:15:35.060436 29269 net.cpp:639] Copying source layer relu4_action
I0928 00:15:35.060439 29269 net.cpp:639] Copying source layer conv5_action
I0928 00:15:35.060444 29269 net.cpp:639] Copying source layer relu5_action
I0928 00:15:35.060447 29269 net.cpp:639] Copying source layer pool5_action
I0928 00:15:35.060451 29269 net.cpp:639] Copying source layer fc6_action
I0928 00:15:35.066581 29269 net.cpp:639] Copying source layer relu6_action
I0928 00:15:35.066601 29269 net.cpp:639] Copying source layer drop6_action
I0928 00:15:35.066604 29269 net.cpp:639] Copying source layer fc7_action
I0928 00:15:35.069524 29269 net.cpp:639] Copying source layer relu7_action
I0928 00:15:35.069531 29269 net.cpp:639] Copying source layer drop7_action
I0928 00:15:35.069535 29269 net.cpp:639] Copying source layer fc8_CAD_action
I0928 00:15:35.069540 29269 net.cpp:639] Copying source layer fc8_CAD_action_fc8_CAD_action_0_split
I0928 00:15:35.069543 29269 net.cpp:639] Copying source layer data_frame
I0928 00:15:35.069546 29269 net.cpp:639] Copying source layer conv1_frame
I0928 00:15:35.069551 29269 net.cpp:639] Copying source layer relu1_frame
I0928 00:15:35.069555 29269 net.cpp:639] Copying source layer pool1_frame
I0928 00:15:35.069558 29269 net.cpp:639] Copying source layer norm1_frame
I0928 00:15:35.069561 29269 net.cpp:639] Copying source layer conv2_frame
I0928 00:15:35.069566 29269 net.cpp:639] Copying source layer relu2_frame
I0928 00:15:35.069569 29269 net.cpp:639] Copying source layer pool2_frame
I0928 00:15:35.069572 29269 net.cpp:639] Copying source layer norm2_frame
I0928 00:15:35.069576 29269 net.cpp:639] Copying source layer conv3_frame
I0928 00:15:35.069748 29269 net.cpp:639] Copying source layer relu3_frame
I0928 00:15:35.069753 29269 net.cpp:639] Copying source layer conv4_frame
I0928 00:15:35.069758 29269 net.cpp:639] Copying source layer relu4_frame
I0928 00:15:35.069761 29269 net.cpp:639] Copying source layer conv5_frame
I0928 00:15:35.069766 29269 net.cpp:639] Copying source layer relu5_frame
I0928 00:15:35.069769 29269 net.cpp:639] Copying source layer pool5_frame
I0928 00:15:35.069772 29269 net.cpp:639] Copying source layer fc6_frame
I0928 00:15:35.076411 29269 net.cpp:639] Copying source layer relu6_frame
I0928 00:15:35.076427 29269 net.cpp:639] Copying source layer drop6_frame
I0928 00:15:35.076431 29269 net.cpp:639] Copying source layer fc7_frame
I0928 00:15:35.079404 29269 net.cpp:639] Copying source layer relu7_frame
I0928 00:15:35.079411 29269 net.cpp:639] Copying source layer drop7_frame
I0928 00:15:35.079416 29269 net.cpp:639] Copying source layer fc8_CAD_frame
I0928 00:15:35.079421 29269 net.cpp:639] Copying source layer prob_frame
I0928 00:15:35.079423 29269 net.cpp:639] Copying source layer prob_action
I0928 00:15:35.079427 29269 net.cpp:639] Copying source layer Data_arrange_layer_filter
I0928 00:15:35.079430 29269 net.cpp:639] Copying source layer concatenation_s_a_p
I0928 00:15:35.079433 29269 net.cpp:639] Copying source layer simplified_message_in
*** Aborted at 1443424540 (unix time) try "date -d @1443424540" if you are using GNU date ***
PC: @     0x7fd2c05ad0d5 (unknown)
*** SIGABRT (@0x3e800007255) received by PID 29269 (TID 0x7fd2c2067940) from PID 29269; stack trace: ***
    @     0x7fd2c0944cb0 (unknown)
    @     0x7fd2c05ad0d5 (unknown)
    @     0x7fd2c05b083b (unknown)
    @     0x7fd2c05ea32e (unknown)
    @     0x7fd2c05f4b26 (unknown)
    @     0x7fd2c1557b8f caffe::CaffeFreeHost()
    @     0x7fd2c1557698 caffe::SyncedMemory::~SyncedMemory()
    @     0x7fd2c15a400e boost::checked_delete<>()
    @     0x7fd2c15a40de boost::detail::sp_counted_impl_p<>::dispose()
    @           0x414884 boost::detail::sp_counted_base::release()
    @           0x4148fd boost::detail::shared_count::~shared_count()
    @     0x7fd2c1524364 boost::shared_ptr<>::~shared_ptr()
    @     0x7fd2c15a37e4 boost::shared_ptr<>::reset<>()
    @     0x7fd2c15988cb caffe::Blob<>::Reshape()
    @     0x7dd27a2a0eaa caffe::Blob_Reshape()
    @     0x7dd27a300253 boost::python::detail::raw_dispatcher<>::operator()()
    @     0x7dd27a2f555f boost::python::objects::full_py_function_impl<>::operator()()
    @     0x7fd2b8e51c6f (unknown)
    @     0x7fd2b8e51ec8 (unknown)
    @     0x7fd2b8e5b0c3 (unknown)
    @     0x7fd2b8e50164 (unknown)
    @     0x7fd2b8a6d083 (unknown)
    @     0x7fd2b89c71fd (unknown)
    @     0x7fd2b89886b5 (unknown)
    @     0x7fd2b898886d (unknown)
    @     0x7fd2b8a6d083 (unknown)
    @     0x7fd2b8a513cf (unknown)
    @     0x7fd2b8a6d083 (unknown)
    @     0x7fd2b8a6d9d7 (unknown)
    @     0x7fd2b8a3d831 (unknown)
    @     0x7dd27a3003f5 boost::python::call_method<>()
    @     0x7dd27a2f5723 caffe::PythonLayer<>::Reshape()
Aborted (core dumped)
